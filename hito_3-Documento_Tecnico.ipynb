{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://desafiolatam.com/assets/home/logo-academia-bla-790873cdf66b0e681dfbe640ace8a602f5330bec301c409744c358330e823ae3.png width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center\"> Documento Técnico Proyecto AutoPGS</div>                                          \n",
    "# <div style=\"text-align: center\"> Automobile Purchase Guide System</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">Nuestra empresa es Data Machine Consulting Group se encarga de realizar consultorías por medio de análisis de datos para una variedad de clientes buscando cumplir con sus objetivos.\n",
    "Realizaremos un reporte completo del proyecto Automobile Purchase Guide System, el cual nace a solicitud de nuestro cliente Automotora Anaconda y consiste en generar una herramienta predictiva que ayude a su equipo de compras a encontrar las mejores oportunidades para la obtención y posterior venta de automóviles usados, mediante una serie de pasos que se detallaran a continuación.\n",
    "\n",
    "Abordaremos temas relevantes que van desde la preparación del ambiente de trabajo, recolección e importación de datos, como también la limpieza, análisis, recodificación y segmentación de los mismos, además del modelamiento y análisis comparativo de los resultados.\n",
    "\n",
    "Por último se realizará la implementación de una aplicación web que permita en base a una cierta cantidad de atributos propios de cada vehículo estimar su valor y realizar una recomendación considerando las políticas propias del negocio y los precios de mercado, que finalmente se traduzcan para nuestros clientes en un aumento de las ventas y una mayor utilidad por cada vehículo  comercializado, como también una mayor rotación de estos y variedad de las unidades disponibles.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del ambiente de trabajo:\n",
    "\n",
    "<p style=\"text-align: justify;\">Antes de comenzar la implementación de este proyecto se requiere importar una serie de librerías que permitan realizar la ingesta, análisis y  modelación de los datos, dentro de los parámetros generales del notebook definiremos la ruta donde se alojaran los archivos csv a utilizar, bases de datos, como también el estilo y tamaño de los plot, gráficos para analizar, y se dejará definido el número de semilla aleatoria que se utilizaran para los distintos modelos.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros generales del notebook\n",
    "ruta_bases = 'bases/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1543b7bd2a08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m from pandas.core.api import (\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0;31m# dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mInt8Dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m from pandas.core.arrays.integer import (\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mInt8Dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mInt16Dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/arrays/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marray_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from .base import (  # noqa: F401\n\u001b[1;32m      3\u001b[0m     \u001b[0mExtensionArray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mExtensionOpsMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mExtensionScalarOpsMixin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/arrays/array_.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtslibs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m from pandas.core.dtypes.common import (\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mis_datetime64_ns_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mis_extension_array_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtslibs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPY36\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import funciones as fn\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import pylab \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ml_classes import PrepML, MLModel\n",
    "from matplotlib.pyplot import rcParams\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge,SGDRegressor\n",
    "from lib.get_nhtsa_json import get_nhtsa_json\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros generales para plots\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = 15, 8\n",
    "plt.style.use('ggplot')\n",
    "# Semilla pseudo-aleatoria\n",
    "rd_seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de los datos\n",
    "\n",
    "<p style=\"text-align: justify;\">Para realizar este proyecto dispondremos de 3 dataset en formato cvs entregados por nuestro cliente, `true_cars_train.csv` y `true_cars_test.csv`, cada uno de ellos contiene 639.145 y 212.977 registros respectivamente, y un tercer dataset bajo el nombre de `true_car_listings.csv`, se reúne la totalidad datos de los dos primeros archivos. \n",
    "\n",
    "Cada una de estos archivos cuentan con ocho atributos propios de cada vehículo dentro de los que tenemos (Precio, Año, Millas, Ciudad, Estado, Vin, Marca y Modelo), dada la poca cantidad de atributos con la que contamos, se hace necesario considerar la búsqueda y extracción de nuevos datos, adicionales a los que ya tenemos para cada vehículo, esto con el propósito de mejorar la exactitud del modelo y lograr una mejor estimación de nuestro vector objetivo `Precio`, para ello utilizaremos el número único identificador de vehículos, o más conocido como `Vin`, el cual es una secuencia de dígitos que identifica los vehículos motorizados de cualquier tipo.\n",
    "\n",
    "El proceso de extracción de estos datos adicionales se realizará utilizando el número único `Vin` que ya tenemos definido para cada vehículo, proceso el cual se logró gracias la creación y ejecución de la función `get_features.py`, mediante la conexión a la API en el sitio web: https://vpic.nhtsa.dot.gov/api/vehicles/DecodeVINValuesBatch/, cabe destacar que esta pagina pertenece a la NHTSA, siendo esta la Administración Nacional de Seguridad del Tráfico en las Carreteras, agencia dependiente del gobierno de los Estados Unidos que reúne la información requerida.\n",
    "\n",
    "A modo de ejemplificar el proceso de extracción de los datos en el siguiente script se presenta una demostración del proceso realizado por la función `get_features.py`, la cual se resume en los siguientes pasos:\n",
    "\n",
    "* 1.- Extraer todos los `Vin` de la base completa `true_car_listings.csv`.\n",
    "* 2.- Requerir a través de la Api 'chunks' de 50 registros por cada petición.\n",
    "* 3.- Guardar en la memoria el json en formato texto, agregando 50 registros por cada iteración.\n",
    "* 4.- Una vez completada las iteraciones guardar en formato json todos los registros requeridos.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Requerimos todos los 'Vin'    \n",
    "all_vins = pd.read_csv(f'{ruta_bases}true_car_listings.csv')['Vin'].to_list()\n",
    "# Parámetros de muestra\n",
    "start = 8\n",
    "end = 8\n",
    "\n",
    "json_text = '['\n",
    "for i in range(start, end+1):\n",
    "    # Generar requerimiento con 50 registros Vin\n",
    "    vin_list = all_vins[50 * (i - 1):50 * i]\n",
    "    json_text += get_nhtsa_json(vin_list, i)\n",
    "\n",
    "# Cerrar lista de Json\n",
    "json_text = json_text[:-2] + ']'\n",
    "# Exportar resultados a archivo json\n",
    "with open(f'api_test/data_{start}_{end}.json', 'w') as json_file:\n",
    "    json_file.write(json_text)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paralelamente, en base a una muestra de la base total, se definió el primer filtro de variables requeridas a través la API: que tengan menos del 10% de datos perdidos, las cuales se presentan a continaución:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "cols = ['AirBagLocFront', 'BodyClass', 'BusFloorConfigType', 'BusType',\n",
    "       'CustomMotorcycleType', 'DisplacementCC', 'DisplacementCI',\n",
    "       'DisplacementL', 'Doors', 'EngineCylinders', 'EngineHP', 'EngineKW',\n",
    "       'ErrorCode', 'ErrorText', 'FuelTypePrimary', 'Make', 'Manufacturer',\n",
    "       'ManufacturerId', 'Model', 'ModelYear', 'MotorcycleChassisType',\n",
    "       'MotorcycleSuspensionType', 'PlantCity', 'PlantCountry', 'TPMS',\n",
    "       'TrailerBodyType', 'TrailerType', 'VIN', 'VehicleType']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estas columnas seleccionadas, se procede a importar los archivos json (varios en el proceso original) para luego mapearlos para retraer solo aquellas columnas, creando un DataFrame con ellas y luego exportarlas en un csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Importación de archivo json\n",
    "filenames = glob.glob('api_test/*.json')\n",
    "json_list = []\n",
    "\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    with open(filename, 'r') as file:\n",
    "        # Mapeamos considerando solo las columnas seleccionadas\n",
    "        data = list(map(fn.get_info, \n",
    "                        json.loads(file.read())\n",
    "                       )\n",
    "                   )\n",
    "    json_list += data\n",
    "\n",
    "# Creación y exortación de DataFrame con features extraídos\n",
    "data_json = pd.DataFrame(data=json_list,\n",
    "                         columns=cols)\n",
    "data_json.to_csv('api_test/data_api.csv')\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ingesta y creación del Dataset \n",
    "\n",
    "Para comenzar con el análisis de los set de datos a utilizar, mediante la función `read_csv` de pandas leemos los archivos `true_cars_train.csv` y `true_cars_test.csv`, adicionalmente a cada uno de estos se les agrega una nueva columna llamada `sample`, la cual permitirá identificar el origen de cada uno de los registros de la base de datos, por último mediante la función `concat` de pandas realizaremos la unión de ambos archivos, pasando así a tener un solo gran archivo dataFrame con la totalidad de los registros, el cual queda bajo el nombre de `df_data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Bases Originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de las bases para muestras de entrenamiento y prueba\n",
    "df_train = pd.read_csv(f'{ruta_bases}true_cars_train.csv',\n",
    "                       delimiter=\";\")\n",
    "df_test = pd.read_csv(f'{ruta_bases}true_cars_test.csv',\n",
    "                      delimiter=\";\")\n",
    "# Dimensiones de las bases\n",
    "print(f'Base Train: {df_train.shape}\\nBase Test: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información general de muestra de entrenamiento\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de atributo 'sample'\n",
    "df_train['sample'] = 'train'\n",
    "df_test['sample'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unión de ambas bases\n",
    "df_data = pd.concat([df_train, df_test])\n",
    "print(f'Base Data: {df_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observaciones__:\n",
    "\n",
    "Mediante `info()`, podemos observar que los atributos del DataFrame no contienen datos nulos, tres de ellos son de tipo númericos `int64` y los restantes cinco son de tipo `objeto`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Base API\n",
    "\n",
    "El archivo obtenido gracias a la función `get_features.py` queda alojado en la carpeta `ruta_bases` bajo el nombre de `api_features.csv`, mediante `read_csv` de pandas realizamos la ingesta de los datos asigandolos al objeto `df_api`, el cual podemos observar que contiene 846.562 registros y 29 columnas que nos proporcionan nuevas caracteristicas para cada cada uno de los `Vin` de los vehiculos consultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de la base extraída por el requerimiento a la api\n",
    "df_api = pd.read_csv(f'{ruta_bases}api_features.csv').drop(columns='Unnamed: 0')\n",
    "print(f'Base API: {df_api.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas con solo valores \"Not Applicable\" \n",
    "notapp_series = df_api\\\n",
    "                    .isin(['Not Applicable'])\\\n",
    "                    .sum()\n",
    "cols2drop = list(notapp_series[notapp_series > 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar aquellas columnas \n",
    "df_api = df_api.drop(columns=cols2drop)\n",
    "print(f'Base API: {df_api.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar columnas\n",
    "df_api=df_api.rename(columns={\"AirBagLocFront\":\"d_AirBagLocFront\",\n",
    "                        \"BodyClass\":\"d_BodyClass\",\n",
    "                        \"DisplacementCC\":\"d_DisplacementCC\",\n",
    "                        \"DisplacementCI\":\"d_DisplacementCI\",\n",
    "                        \"DisplacementL\":\"d_DisplacementL\",\n",
    "                        \"Doors\":\"d_Doors\",\n",
    "                        \"EngineCylinders\":\"d_EngineCylinders\",\n",
    "                        \"EngineHP\":\"d_EngineHP\",\n",
    "                        \"EngineKW\":\"d_EngineKW\",\n",
    "                        \"ErrorCode\":\"d_ErrorCode\",\n",
    "                        \"ErrorText\":\"d_ErrorText\",\n",
    "                        \"FuelTypePrimary\":\"d_FuelTypePrimary\",\n",
    "                        \"Make\":\"d_Make\",\n",
    "                        \"Manufacturer\":\"d_Manufacturer\",\n",
    "                        \"ManufacturerId\":\"d_ManufacturerId\",\n",
    "                        \"Model\":\"d_Model\",\n",
    "                        \"ModelYear\":\"d_ModelYear\",\n",
    "                        \"PlantCity\":\"d_PlantCity\",\n",
    "                        \"PlantCountry\":\"d_PlantCountry\",\n",
    "                        \"TPMS\":\"d_TPMS\",\n",
    "                        \"VIN\":\"Vin\",\n",
    "                        \"VehicleType\":\"d_VehicleType\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observaciones:__\n",
    "\n",
    "Mediante `info()`, podemos observar que los atributos del DataFrame `df_api`, son de tipo objeto y float, se identifica además que existen datos tipificados como `Not Applicable`, los cuales se proceden a eliminar debido a que no generan un mayor aporte al desarrollo del proyecto, finalmente se renombran las columnas con el propósito de lograr una mejor identificación de cada atributo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Unión de Bases\n",
    "\n",
    "Ya con los archivos asignados a los Dataframes `df_data` y `df_api`, se procede mediante el método `merge` a su unión, en donde se utiliza el numero `Vin` como llave para generar la intercepción de los datos, quedando así una única gran base de 846.644 registros y 30 columnas, la cual se asigna bajo el nombre de `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unión de bases\n",
    "df = pd.merge(left=df_data, \n",
    "              right=df_api, \n",
    "              how='inner',\n",
    "              on='Vin')\n",
    "# Dimensiones de la base\n",
    "print(f'Dataset: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información general del dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observaciones:__\n",
    "\n",
    "Mediante la función `info()` aplicado al `df` final (que contiene la unión de ambos archivos), podemos observar que los atributos del DataFrame son de tipo `int`, `objet` y `float`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Limpieza del Dataset\n",
    "\n",
    "Dentro de los nuevos atributos obtenidos se destaca la columna `ErrorText`, la cual entrega información relevante respecto a la extracción de los datos e indica en ella si los atributos asociados al numero `Vin` se extrajeron de manera exitosa, es por esto que se toma la decisión de mantener solo aquellos datos que se obtuvieron de manera correcta pasando de tener en un inicio 846.644 a 845.778 registros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 ErrorText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisamos la columna ErrorText, que entrega información respecto errores en la extracción de los datos\n",
    "df['d_ErrorText'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se mantienen solo los datos extraídos correctamente\n",
    "df = df[(df['d_ErrorText'] == '0 - VIN decoded clean. Check Digit (9th position) is correct') |\n",
    "       (df['d_ErrorText'] == '0 - VIN decoded clean. Check Digit (9th position) is correct; 14 - Unable to provide information for all the characters in the VIN.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se eliminan las columnas de error que ya utilizamos\n",
    "df = df.drop(columns=[\"d_ErrorCode\",\"d_ErrorText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de atributo\n",
    "df[\"d_EngineCylinders\"] = df[\"d_EngineCylinders\"].map(lambda x: float(str(x)\\\n",
    "                                                                   .replace('12, 8', '12')\\\n",
    "                                                                   .replace('8, 12', '8'))\n",
    "                                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observaciones:__\n",
    "\n",
    "Para asegurar la calidad de los datos solo se mantendrán aquellos registros que fueron decodificados de manera correcta, adicionalmente a esto, se recodifican los datos de la columna `d_EngineCylinders`, dejándolos todos de tipo `float` para evitar posteriores errores al momento de graficar esta variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Nulos, datos duplicados y columnas duplicadas\n",
    "\n",
    "<p style=\"text-align: justify;\">Una de las consideraciones que se debe tener presente al momento de trabajar con grandes volúmenes de datos son precisamente los datos nulos, duplicados y columnas duplicadas, ya que estos pueden afectan el desarrollo del proyecto, tanto en la parte de análisis de los datos como en el entrenamiento y modelación. Es por esto que se decide eliminar las columnas duplicadas, como también  aquellas que presenten sobre el 0.15 % de datos nulos, asegurando así la calidad e integridad de los mismos.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos nulos\n",
    "#Mediante \"isnull()\", sum() y shape() identificamos los atributos con datos nulos y su procentaje relativo.\n",
    "null = round(df.isnull().sum()/df.shape[0],2) \n",
    "null[null>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas con más de un 15% de datos perdidos y luego los eliminamos\n",
    "null_series = df_api\\\n",
    "                .isnull()\\\n",
    "                .sum()\\\n",
    "                /df_api.shape[0] \n",
    "df = df.drop(columns=list(null_series[null_series > .15].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos duplicados\n",
    "#Observamos la cantidad de registros duplicados en el df.\n",
    "duplicate_rows_df = df[df.duplicated()]\n",
    "duplicate_rows_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los registros duplicados\n",
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas duplicadas\n",
    "# Chequemos si la columna Model, (data set de la academia) y la columna d_Model (data de la API) son iguales.\n",
    "(df.Model==df.d_Model).value_counts(\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos los primeros 5 registros de model y d_model.\n",
    "df[['Model', 'd_Model']] .head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chequemos si la columna Make, (data set de la academia) y la columna d_Make (data de la API) son iguales.\n",
    "(df.Make==df.d_Make).value_counts(\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores unicos columna make.\n",
    "np.unique(df.Make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores unicos columna d_make.\n",
    "np.unique(df.d_Make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chequemos si la columna Year, (data set de la academia) y la columna d_ModelYear (data de la API) son iguales.\n",
    "(df.Year == df.d_ModelYear).value_counts(\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación columnas duplicadas provenientes de la API.\n",
    "df = df.drop(columns=['d_Make',\"d_Model\",\"d_ModelYear\", 'd_ManufacturerId',\n",
    "                      'd_DisplacementCI', 'd_DisplacementL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de variables no informativas\n",
    "df = df.drop(columns=['Vin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observaciones:__\n",
    "\n",
    "<p style=\"text-align: justify;\">En general podemos observar que los porcentajes de valores nulos por atributo son bastante bajos, a excepción de `d_engineHP`, `d_EngineKW`, `d_TPMS` y `PlantCity`, los cuales superan el 0.15 % definido en un comienzo, bajo este escenario se procede a eliminarlos del dataset. \n",
    "\n",
    "Respecto a los registros y columnas duplicadas, se detectan 161 registros bajo esta condición, por lo que se procede a su exclusión, se decide también eliminar las columnas `d_Make`, `d_Model`, `d_modelYear`, `d_ManufacterID`, `d_DisplacenemetCI` y `d_DisplacementL` que se obtuvieron gracias a la extracción de datos desde la API ya que están duplicadas, y no entregan un mayor aporte al proyecto.\n",
    "\n",
    "Dentro de los criterios que se utilizaron para definir la eliminación de atributos duplicados, tenemos  el caso  `d_Make` el cual al compararlo con el atributo original `Make`, podemos observar que  los nombres de las marcas no vienen normalizados, ademas de contener una menor cantidad de información, por otra parte al contrastar  `d_Model` con la columna original `Model`, se observa que esta contiene una menor cantidad de datos, criterios como estos se tomaron en consideraron al momento de la eliminación de atributos, quedándonos finalmente con un DataFrame que se conforma de 845.617 registros y 17 columnas.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspección general después de limpieza\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Análisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Distribución vector objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">Al observar la distribución del atributo precio (vector objetivo), podemos ver que este es muy variable, teniendo registros con valores muy bajos que parten en los  USD 1.500  como también otros que se escapan del promedio de forma destacada alcanzando hasta los USD 499.500. También observamos que la mayoría de los datos se encuentran entre los rangos 1.500 a 100.000 USD. \n",
    "\n",
    "Lo anterior se debe a que dentro de la BDD tenemos diferentes tipos de vehículos cada uno de estos con precios y características propias, por lo que a modo de segmentar estos atributos se decide renombrar las columnas según la tipologías asociadas al uso, tipo de vehículo, características técnicas, ubicación y lugar de fabricación, definiendo de este modos una mejor forma de analizar dichos atributos.</p>\n",
    "\n",
    "- `USE (USE)`:Atributos relacioados al uso del auto:\n",
    "    * __Year__, \n",
    "    * __Mileage__\n",
    "\n",
    "- `SEGMENT (SGT)`:Atributos asociados al tipo de vehículo:\n",
    "    * __Vehiculetype__, \n",
    "    * __Bodyclass__, \n",
    "    * __Make__, \n",
    "    * __Model__, \n",
    "    * __Manufacture__\n",
    "\n",
    "- `FEATURES (FEAT)`:Atributos asociados las características técnicas del vehículo:\n",
    "    * __Fuel type__, \n",
    "    * __Airbag__, \n",
    "    * __Displacement__,\n",
    "    * __Doors__, \n",
    "    * __EngineCylindren__\n",
    "\n",
    "- `LOCALIZATION (LOC)`:Atributos asociados a la ubicación del vehículo:\n",
    "    * __State__,\n",
    "    * __City__\n",
    "\n",
    "- `FABRICATION(FAB)`:Atributo de ubicación de la fabricación:\n",
    "    * __Plantcountry__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## observamos la distribución del precio mediante un histograma y un gráfico de cajas y bigotes.\n",
    "fn.distrbution_graph(df.Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se renombran los atributos, según lo indicado anteriormente\n",
    "df=df.rename(columns={\"d_AirBagLocFront\":\"feat_AirBagLocFront\",\n",
    "                        \"d_DisplacementCC\":\"feat_DisplacementCC\",\n",
    "                        \"d_Doors\":\"feat_Doors\",\n",
    "                        \"d_EngineCylinders\":\"feat_EngineCylinders\",\n",
    "                        \"d_EngineHP\":\"feat_EngineHP\",\n",
    "                        \"d_EngineKW\":\"feat_EngineKW\",\n",
    "                        \"d_TPMS\":\"feat_TPMS\",\n",
    "                        \"EngineCylinders\":\"feat_EngineCylinders\",  \n",
    "                        \"d_FuelTypePrimary\":\"feat_FuelTypePrimary\",\n",
    "                        \"d_BodyClass\":\"sgt_BodyClass\",  \n",
    "                        \"d_Manufacturer\":\"sgt_Manufacturer\",\n",
    "                        \"d_VehicleType\":\"sgt_VehicleType\",  \n",
    "                        \"Model\":\"sgt_Model\",\n",
    "                        \"Make\":\"sgt_Make\",\n",
    "                        \"d_PlantCity\":\"fab_PlantCity\",\n",
    "                        \"d_PlantCountry\":\"fab_PlantCountry\",\n",
    "                        \"Year\":\"use_Year\",\n",
    "                        \"Mileage\":\"use_Mileage\",\n",
    "                        \"City\":\"loc_City\",\n",
    "                        \"State\":\"loc_State\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Distribución y relaciones de los atributos con el vector objetivo:\n",
    " \n",
    "A continuación se realizaran una serie de gráficos para observar el comportamiento de los atributos asociados a las características técnicas del vehículo como son: `Fuel type`, `Airbag`, `Displacement`, `Doors` y `EngineCylindren`, además de realizar una matriz de correlación de los atributos de tipo numérico con el vector objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Atributos features (feat):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1.1 Matriz de correlación entre atributos \"feat\" númericos u ordinales con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos lista con columnas feat\n",
    "col_names_feat = [col for col in df.columns if 'feat' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos df con columnas feat más Price para hacer la matrix de correlación\"\n",
    "df_feat = df[col_names_feat]\n",
    "df_feat[\"Price\"] = df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos matriz de correlación entre los atributos númericos u ordinales y nuestro vector objetivo precio.\n",
    "f,ax = plt.subplots(figsize=(6, 4))\n",
    "sns.heatmap(df_feat.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1.2 Distribución y relación de los atributos categóricos \"feat con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable \"feat_airbag\"\n",
    "fn.count_box_plot('feat_AirBagLocFront', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable \"feat_Doors\"\n",
    "fn.count_box_plot(\"feat_Doors\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable \"feat_EngineCylinders\"\n",
    "fn.count_box_plot(\"feat_EngineCylinders\",df, 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fn.count_box_plot(\"feat_FuelTypePrimary\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observaciones:__\n",
    "\n",
    "- Los atributos `feat_Doors`, `feat_Airbag` y `feat_FuelType` están considerablemente desbalanceadas hacia una categoría, por lo que no se recomienda utilizar estas variables para el modelamiento de datos.\n",
    "- `Displacement` presentan una correlación de 0.3 con el vector objetivo y se sugiere considerarla en el modelamiento. \n",
    "- Respecto a la variable `feat_EngineCylinders` presenta una correlación positiva con el precio de 0.4, por lo que también es un atributo candidato para ser utilizado en el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Distribución atributos Use:\n",
    "\n",
    "Se realizará una serie de gráficos para observar el comportamiento de los atributos asociados al `uso` del vehículo como lo son: `Year` y `Mileage`, además de generar una matriz de correlación de estos con el vector objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2.1 Matriz de correlación entre atributos \"Use\" númericos u ordinales con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos lista con columnas feat\n",
    "col_names_use = [col for col in df.columns if 'use' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos df con columnas use más Price para hacer la matrix de correlación\"\n",
    "df_use = df[col_names_use]\n",
    "df_use[\"Price\"] = df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos matriz de correlación entre los atributos númericos u ordinales y nuestro vector objetivo precio.\n",
    "f,ax = plt.subplots(figsize=(6, 4))\n",
    "sns.heatmap(df_use.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2.2 Distribución y relación de los atributos categóricos \"Use\" con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable use_Mileage\n",
    "fn.distrbution_graph(df.use_Mileage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observamos la distribución de use_Mileage en función del precio, mediante un scatterplot.\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.scatterplot(y=df['Price'], x=df['use_Mileage']);\n",
    "plt.title('Mileage and Price relation ',fontsize=15,color='blue',fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Variable \"Year\"\n",
    "fn.count_box_plot(\"use_Year\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observaciones:__\n",
    "\n",
    "- Existe una asociación positiva de 0.4 entre `Year` y el `precio` de vehículos.\n",
    "- Existe una asociación negativa de 0.4 entre `Mileage` y el `precio` de los vehículos.\n",
    "- Entre `year` y `Mileage` exite una fuerte asociación negativa de 0.8;  Dada esta asociación, quizás es recomendable considerar solo uno de estos atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Distribución atributos localization (loc):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3.1 Distribución y relación de los atributos categóricos \"Loc\" con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable loc_state\n",
    "fn.count_box_plot(\"loc_State\",df, 70000,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# observamos la distribución de loc_City, mediante un plot\n",
    "df['loc_City'].value_counts().head(30).plot(kind='barh', figsize=(6,10))\n",
    "plt.title('City Distribution',fontsize=15,color='blue',fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observaciones:__\n",
    "\n",
    "- El precio por `State` (estado) presenta una distribución similar, esto se evidencia al observar los cuartiles y la mediana de los precios en cada uno de los estados, solo el estado `DC` presenta precios inferiores, se recomienda no considerar esta variable por el momento.\n",
    "\n",
    "- Dada la complejidad en cuanto al número de ciudades contenidas en la base de datos, por ahora no recomendamos utilizar esta variable en el proceso de entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Distribución atributos de segmentacion (sgt):\n",
    "\n",
    "A continuación se realizaran una serie de gráficos para observar el comportamiento de los atributos asociados a la `segmentación` o tipologia de los vehículos como lo son: `Vehiculetype`, `Bodyclass`, `Make`, `Model`, `Manufacture`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4.1 Distribución y relación de los atributos categóricos \"de segmentación \"SGT\" con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable sgt_BodyClass\n",
    "fn.count_box_plot(\"sgt_BodyClass\",df, 100000,False)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Variable sgt_VehicleType\n",
    "fn.count_box_plot(\"sgt_VehicleType\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Variable sgt_Manufacter\n",
    "fn.count_box_plot(\"sgt_Manufacturer\", df, 100000,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable sgt_Make\n",
    "fn.count_box_plot(\"sgt_Make\", df, 500000,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observamos la distribución de sgt_model, mediante un plot\n",
    "df['sgt_Model'].value_counts().head(30).plot(kind='barh', figsize=(6,10))\n",
    "plt.title('Model Distribution',fontsize=15,color='blue',fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observaciones:__\n",
    "\n",
    "Los atributos `BodyClass`, `VehicleType`, `Make`, `Model` y `Manufacter` muestran variaciones de los precios por categoría. Sin embargo, existen muchas categorías para estas variables con frecuencias además muy bajas, lo que puede afectar los resultados al momento de utilizarlas para el proceso de modelación sin realizar algun tipo de segmentación previa, es por esto que se recomienda utilizar dichas variables previa a la reorganización de las categorías marginales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Distribución atributos de fabricación (fab):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se realizarán gráficos para observar el comportamiento del atributo asociados al lugar de `fabricación`de los vehículos: `PlanCountry`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5.1 Distribución y relación de los atributos categóricos de fabricación \"fab\" con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable fab_PlantCountry\n",
    "fn.count_box_plot(\"fab_PlantCountry\",df, 100000,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observaciones:__\n",
    "\n",
    "El atributo `PlantCountry` muestra variación de los precios entre paises, sin embargo, también se observan frecuencias de paises marginales, por lo que se recomienda utilizar esta variable para el entrenamiento de los datos, previa su recategorización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Segmentación de variables\n",
    "\n",
    "## 3.1 Segmentación de fab_PlantCountry\n",
    "\n",
    "Una de las consideraciones que se debe tener presente cuando se cuenta con atributos que presentan categorías marginales, es la reagrupación o segmentación de estos, de modo tal que estas categorías minoritarias no interfieran al momento de la modelación, es por esto que para el atributo `fab_PlantCountry`, se decide segmentar en nuevas categorías el 4.3% de los datos, los cuales se encuentran distribuidos en una serie de países que presentan estas cantidades más bajas, por lo tanto se decide crear dos nuevas categorías que los agrupen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reagrupamos el atributo fab_PlantCountry\n",
    "df['fab_PlantCountry'] = df['fab_PlantCountry'].replace(\n",
    "                         ['FRANCE','SPAIN', 'PORTUGAL', 'POLAND', 'NETHERLANDS', 'SERBIA', 'FINLAND',\"ITALY\",\"UNITED KINGDOM (UK)\",\"AUSTRIA\",\"HUNGARY\",\"ENGLAND\",\"BELGIUM\",\"SWEDEN\",\"SLOVAKIA\"],'OTHERS_EUROPE').replace(\n",
    "                         ['ARGENTINA','VENEZUELA', 'BRAZIL', 'UNITED STATES (USA), CANADA', 'CANADA, UNITED STATES (USA)'],'OTHERS_AMERICA').replace(\n",
    "                         ['THAILAND','TURKEY', 'CHINA', 'AUSTRALIA', 'INDIA'],'OTHERS_ASIA_OCEANIA').replace(\n",
    "                         [\"OTHERS_AMERICA\",\"OTHERS_ASIA_OCEANIA\",\"SOUTH AFRICA\"],\"OTHER_COUNTRIES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vusalizamos la cantidad de datos para c/u de las variables de fab_PlantCountry\n",
    "df.fab_PlantCountry.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observaciones:__\n",
    "\n",
    "Las categorías que estan por debajo de los 5.613 registros, se reagrupan en dos nuevas categorias llamadas `OTHER_EUROPE` y `OTHER_COUNTRY`, pasando así de tener en un inicio treinta y dos categorias, paises de fabricación, a tan solo ocho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Segmentación de sgt_BodyClass\n",
    "\n",
    "Otra de las segmentaciones que se hace necesaria realizar es la del atributo `BodyClass`, el cual hace referencia a la  clase de vehículo que se tiene registrado, dentro de las categorías de este atributo nos encontramos con vehículos que se registran con cantidades muy marginales como lo son `Bus`, `Limousine` y `Trailer`, alcanzando estas un total del 0.015% registros, por otro lado se presentan registros bajo tipología de `Incompleto` los que alcanzan el  un total de 1.7% registros, es por esto que se decide eliminar dichas categorías, ya que son muy marginales y no presentan un aporte significativo para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reagrupamos el atributo sgt_BodyClass\n",
    "df['sgt_BodyClass'] = df['sgt_BodyClass'].replace(\n",
    "                      [\"Hatchback/Liftback/Notchback, Convertible/Cabriolet\"],\"Hatchback/Liftback/Notchback\").replace(\n",
    "                      [\"Wagon, Sport Utility Vehicle (SUV)/Multi-Purpose Vehicle (MPV)\"],\"Wagon\").replace(\n",
    "                      [\"Incomplete - Cutaway\",\"Incomplete - Cutaway\",\"Incomplete - Chassis Cab (Number of Cab Unknown)\",\"Incomplete - Chassis Cab (Double Cab)\",\"Incomplete - Stripped Chassis\",\"Incomplete - Commercial Chassis\",\"Incomplete - Motor Home Chassis\",\"Incomplete - Chassis Cab (Single Cab)\",\"Incomplete - Chassis Cab (Double Cab) \"],\"Incomplete\").replace(\n",
    "                      [\"Truck\"],\"Sport Utility Truck (SUT)\").replace(\n",
    "                      [\"Roadster\"],\"Convertible/Cabriolet\").replace(\n",
    "                      [\"Cargo Van\"],\"Minivan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazamos con np.nan, aquellas variables del atributo sgt_BodyClass que tienen una frecuencia marginal \n",
    "df = df.replace({'sgt_BodyClass':{\"Bus\":np.NaN,\"Limousine\":np.NaN,'Trailer':np.NaN,\"Incomplete\":np.NaN}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vusalizamos la cantidad de datos para c/u de las variables de sgt_BodyClass\n",
    "df.sgt_BodyClass.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observaciones:__\n",
    "\n",
    "Se agrupan las categorías según automóviles similares, El criterio utilizado fue juicio experto, aquellas categorías que presentan una menor cantidad de registros y categorías tipificadas como `incompleto`, se decide transformarlas a NaN, dentro de las que tenemos `Bus`, `Limousine` e `Incomplete`, como resultado pasamos de tener veintiséis a un total de once clases de vehículos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Segmentación de sgt_VehicleType\n",
    "\n",
    "Al revisar el atributo `VehicleType` que hace referencia al tipo de vehiculo registrado, podemos observar que esta tiene 5 categorias de vehiculos, de las cuales tres concentran la mayor parte de los datos, el 99.6 % de estos. \n",
    "\n",
    "Estas categorias son: `Vehiculos de pasajeros`, `Vehiuclos Multiproposito` y `Camionetas`, es por esto que uno de los criterios de eliminación fue no considerar el 0.4% de los registros que hacen referencia a `Vehiculos incompletos` y `Buses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazamos con np.nan, aquellas variables del atributo sgt_VehicleType que tienen una frecuencia marginal \n",
    "df = df.replace({'sgt_VehicleType':{\"INCOMPLETE VEHICLE\":np.NaN,\"BUS\":np.NaN,\"TRAILER\":np.NaN}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vusalizamos los Q para c/u de las variables de sgt_VehicleType\n",
    "df.sgt_VehicleType.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observaciones:__\n",
    "\n",
    "Dado que dentro del atributo `sgt_VehicleType` tenemos variables con una frecuencia muy marginal, se decide no considerarlas, por lo que se transforman a np.nan, quedandonos solo con tres categorias de vehiculo:\n",
    "\n",
    "* De pasajeros\n",
    "* Multiproposito\n",
    "* Camión\n",
    "\n",
    "Lo cual está muy relacionado con los tipos de vehiculos que se comercializan en una compra venta de vehiculos Usados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Eliminación de Modelos de Vehiculos con menos de 30 observaciones\n",
    "\n",
    "Para mejorar el rendimiento del modelo como último filtro se decidió eliminar los modelos de vehículos que presentan menos de 30 registros, esto porque se consideran como un dato marginal que no aporta mayormente al rendimiento del modelo predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar 30 modelos\n",
    "modelos = df['sgt_Make'].value_counts()\n",
    "df = df[df['sgt_Make'].isin(modelos[modelos > 30].index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Reagrupación de variable año"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cómo la variable año refleja la antiguedad de un vehículo al compararla con un año de referencia (2018 para la base de entrenamiento/prueba), se hace está trasnformación para generar la variable de 'edad' del vehículo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recodificación de variable año \n",
    "df['use_Age'] = 2018 - df['use_Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Preproceso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante esta etapa se realiza el preprocesamiento necesario de los atributos y vector objetivo para que puedan ser utilizados para entrenar y probar posteriormente en modelos de ML. Primero procedemos a liberar algo de espacio en la memoria RAM borrando las variables usadas durante la construcción del dataset, para luego proceder a la selección de atributos y el muestreo aleatorio de datos a preprocesar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberar Espacio Memoria\n",
    "del df_api\n",
    "del df_data\n",
    "del df_train\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de atributos para el entrenamiento:\n",
    "Como resultado del Análisis de la distribución de los atributos y de la relación de ellos con el vector objetivo se decide seleccionar 5 atributos para la fase de entrenamiento de modelos:\n",
    "0. Price (Vector Objetivo)\n",
    "1. Mileage\n",
    "2. BodyClass\n",
    "3. VehicleType\n",
    "4. Model\n",
    "5. Age\n",
    "6. EngineCylinders\n",
    "7. DisplacementCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de variables para modelos\n",
    "select_vars = ['Price', 'use_Mileage', 'use_Age', 'sample', \n",
    "               'sgt_BodyClass', 'sgt_Make', 'sgt_VehicleType',\n",
    "               'feat_DisplacementCC', 'feat_EngineCylinders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra aleatoria\n",
    "df_sample = df[select_vars]\\\n",
    "                .dropna()\\\n",
    "                .reset_index(drop=True)\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A través de la clase `PrepMl` se realizarán los tres preprocesos seleccionados para esta modelación: __Remove_Outliers__, __OneHot_Encoder__ y __Standard_Scaler__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar clase para realizar preproceso\n",
    "df_prep = PrepML(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de Outliers\n",
    "df_prep.remove_outliers(['Price', 'use_Mileage', 'use_Age', \n",
    "                         'feat_DisplacementCC', 'feat_EngineCylinders'], \n",
    "                        iqr_multiplier=1.5, print_diff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos OneHot Encoder a las columnas categóricas seleccionadas\n",
    "df_prep.one_hot_encoder(['sgt_BodyClass', 'sgt_Make', 'sgt_VehicleType'],\n",
    "                        drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizamos variables continuas seleccionadas\n",
    "df_prep.standard_scaler(['use_Mileage', 'use_Age', 'feat_DisplacementCC', 'feat_EngineCylinders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar muestras según\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = df_prep.to_ml_samples('sample', 'Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modelamiento "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A través de la clase `MLModel` se entrenarán y se realizará una busqueda de grilla para encontrar los mejores hiperparámetros por modelo, y posteriormente evaluar cada mejor modelo con la muestra de prueba. \n",
    "\n",
    "Es decir, serán cuatro modelos a entrenarse, dos paramétricos (`Ridge Regression` y `Stochastic Gradient Descent Regression`) y dos no-paramétricos (`XGBoost` y `LightGBM`, ambas implementaciones de Gradient Boosting).\n",
    "\n",
    "Primero, se comienza con el entrenamiento de prueba de una Regresión Lineal, para corroborar que no hay errores en el preproceso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Modelo Único"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Establecemos parámetros a evaluar en el modelo\n",
    "ridge_grid = {'alpha': [0, .001, 0.0001],\n",
    "              'solver': ['sag', 'sparse_cg']}\n",
    "# Instanciamos Clase auxiliar para entrenar, ajustar y evaluar modelos de ML\n",
    "ridge_reg = MLModel(model=Ridge(fit_intercept=True))\n",
    "# Implementación del grid search\n",
    "ridge_reg.grid_search(X_train,\n",
    "                      y_train,\n",
    "                      param_grid=ridge_grid,\n",
    "                      n_jobs=-2,\n",
    "                      cv=5)\n",
    "# Serialización del mejor modelo\n",
    "ridge_reg.to_pickle(car_category='allcars')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos mejor modelo\n",
    "ridge_best = MLModel.from_pickle('best_models/allcars_ridge.sav')\n",
    "# Métricas mejor modelo\n",
    "ridge_best.train_val_metrics(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Stochastic Gradient Descent Regression (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Establecemos parámetros a evaluar en el modelo\n",
    "sgd_grid = {'loss': ['squared_epsilon_insensitive', 'squared_loss'],\n",
    "            'alpha': [0, 0.0001, 0.00001]\n",
    "          }\n",
    "# Instanciamos Clase auxiliar para entrenar, ajustar y evaluar modelos de ML\n",
    "sgd_reg = MLModel(model=SGDRegressor(penalty = 'l1',\n",
    "                                     early_stopping = False,\n",
    "                                     random_state=rd_seed))\n",
    "# Implementación del grid search\n",
    "sgd_reg.grid_search(X_train,\n",
    "                    y_train,\n",
    "                    param_grid=sgd_grid,\n",
    "                    n_jobs=-2,\n",
    "                    cv=5)\n",
    "# Serialización del mejor modelo\n",
    "sgd_reg.to_pickle(car_category='allcars')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos mejor modelo\n",
    "sgd_best = MLModel.from_pickle('best_models/allcars_sgdregressor.sav')\n",
    "# Métricas mejor modelo\n",
    "sgd_best.train_val_metrics(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Establecemos parámetros a evaluar en el modelo\n",
    "lgb_grid = {'max_depth': [11, 12, 13], \n",
    "            'num_leaves': [125, 135, 145]}\n",
    "# Instanciamos Clase auxiliar para entrenar, ajustar y evaluar modelos de ML\n",
    "lgb_reg = MLModel(model=LGBMRegressor(n_jobs=1,\n",
    "                                      random_state=rd_seed))\n",
    "# Implementación del grid search\n",
    "lgb_reg.grid_search(X_train,\n",
    "                    y_train,\n",
    "                    param_grid=lgb_grid,\n",
    "                    n_jobs=-2,\n",
    "                    cv=5)\n",
    "# Serialización del mejor modelo\n",
    "lgb_reg.to_pickle(car_category='allcars')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos mejor modelo\n",
    "lgb_best = MLModel.from_pickle('best_models/allcars_lgbmregressor.sav')\n",
    "# Métricas mejor modelo\n",
    "lgb_best.train_val_metrics(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4 XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Establecemos parámetros a evaluar en el modelo\n",
    "xgb_grid = {'max_depth': [7, 8, 9], \n",
    "            'n_estimators': [80, 90, 100]}\n",
    "# Instanciamos Clase auxiliar para entrenar, ajustar y evaluar modelos de ML\n",
    "xgb_reg = MLModel(model=XGBRegressor(objective ='reg:squarederror',\n",
    "                                     n_jobs=1,\n",
    "                                     seed=rd_seed))\n",
    "# Implementación del grid search\n",
    "xgb_reg.grid_search(X_train,\n",
    "                    y_train,\n",
    "                    param_grid=xgb_grid,\n",
    "                    n_jobs=2,\n",
    "                    cv=3)\n",
    "# Serialización del mejor modelo\n",
    "xgb_reg.to_pickle(car_category='allcars')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos mejor modelo\n",
    "xgb_best = MLModel.from_pickle('best_models/allcars_xgbregressor.sav')\n",
    "# Métricas mejor modelo\n",
    "xgb_best.train_val_metrics(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comentarios Generales__:\n",
    "    \n",
    "De los resultados obtenidos podemos concluir apriori que:  \n",
    "1.- Existen relaciones no lineales en la variables que se refleja en la superioridad de los modelos basados en árboles de decisión sobre los modelos lineales. Estos resultados son consistentes con los análisis  intermedios y exploratorios.  \n",
    "2.- Modelando solo un modelo para calcular el precio de mercado, obtuvimos resultados que alentarían el uso de un único modelo para predecir todos los casos, aunque no se descarta la alterantiva de grupos de modelos para predecir dividendo por alguna categoría queda pendiente a evaluarse en los próximos pasos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Modelos Múltiples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos la muestra según las categorías en `VehicleType`, dado que cada las tres categorías que representa esta variable, divide los autos según la principal función del vehículo: de pasajeros, multipropósito y camiones (para carga). Esta división representaría de mejor forma la relación de los atributos en el precio del vehículo. A continuación, preparamos las muestras para entrenar y evaluar los distintos modelos por categoría de vehículo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de diccionarios con tipo de vehículos\n",
    "car_dict = {'psg': 'PASSENGER CAR', \n",
    "            'mpp': 'MULTIPURPOSE PASSENGER VEHICLE (MPV)', \n",
    "            'trk': 'TRUCK '}\n",
    "# Lista con tipo de muestras a crearse\n",
    "sample_list = ['X_train', 'y_train', 'X_test', 'y_test', 'X_val', 'y_val']\n",
    "samples = {}\n",
    "\n",
    "for cat, car_type in car_dict.items():\n",
    "    \n",
    "    # Instanciar clase para realizar preproceso\n",
    "    prep = PrepML(df_sample[df_sample['sgt_VehicleType'] == car_type]\\\n",
    "                            .reset_index(drop=True)\n",
    "                            .drop(columns='sgt_VehicleType'))\n",
    "    # Eliminación de Outliers\n",
    "    prep.remove_outliers(['Price', 'use_Mileage', 'use_Age', 'feat_DisplacementCC', \n",
    "                             'feat_EngineCylinders'], iqr_multiplier=1.5,\n",
    "                              print_diff=False)\n",
    "    # Realizamos OneHot Encoder a las columnas categóricas seleccionadas\n",
    "    prep.one_hot_encoder(['sgt_BodyClass', 'sgt_Make'],\n",
    "                            drop_first=True)\n",
    "    # Estandarizamos variables continuas seleccionadas\n",
    "    prep.standard_scaler(['use_Mileage', 'use_Age', 'feat_DisplacementCC', \n",
    "                             'feat_EngineCylinders'])\n",
    "    # Separar muestras\n",
    "    samples[cat] = {i: j for i, j in zip(sample_list, \n",
    "                                         prep.to_ml_samples('sample', 'Price'))}\n",
    "    # Agregamos los transformadores\n",
    "    samples[cat].update({'transformers': prep.transformers})\n",
    "    # Agregamos muestra para entrenar el objeto ColumnTransformer para serializar los modelos\n",
    "    samples[cat].update({'df_ct': prep.df_ct})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos los modelos y grillas de hiperparámetros a evaluarse en las 3 categorías de vehículos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista con modelos\n",
    "ridge_model = Ridge(fit_intercept=True)\n",
    "sgd_model = SGDRegressor(penalty = 'l1',\n",
    "                       early_stopping = False,\n",
    "                       random_state=rd_seed)\n",
    "lgb_model = LGBMRegressor(n_jobs=1,\n",
    "                        random_state=rd_seed)\n",
    "xgb_model = XGBRegressor(objective ='reg:squarederror',\n",
    "                       n_jobs=1,\n",
    "                       seed=rd_seed)\n",
    "\n",
    "model_list = [ridge_model, sgd_model, lgb_model, xgb_model]\n",
    "\n",
    "# Lista con grilla de hiperparámetros\n",
    "ridge_grid = {'alpha': [0, .001, 0.0001],\n",
    "              'solver': ['sag', 'sparse_cg']\n",
    "             }\n",
    "sgd_grid = {'loss': ['squared_epsilon_insensitive', 'squared_loss'],\n",
    "            'alpha': [0, 0.0001, 0.00001]\n",
    "           }\n",
    "lgb_grid = {'max_depth': [11, 12, 13], \n",
    "           'num_leaves': [110, 120, 130]\n",
    "           }\n",
    "xgb_grid = {'max_depth': [7, 8, 9], \n",
    "            'n_estimators': [80, 90, 100]\n",
    "           }\n",
    "\n",
    "grid_list= [ridge_grid, sgd_grid, lgb_grid, xgb_grid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora pasamos a entrenar los modelos por categoría de `VehicleType`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Modelos Passenger Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la categoría de vehículo a modelar \n",
    "category = 'psg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Entrenamos, ajustamos hiperparámetros y serializamos modelos\n",
    "# (muestra de lo que hace la función train_mlmodels)\n",
    "for model, grid in zip(model_list, grid_list):\n",
    "    \n",
    "    print(f'{category}_{model.__class__.__name__.lower()}')\n",
    "    # Instanciamos Clase auxiliar para entrenar, ajustar y evaluar modelos de ML\n",
    "    model_reg = MLModel(model=model)\n",
    "    # Implementación del grid search\n",
    "    model_reg.grid_search(samples[category]['X_train'],\n",
    "                          samples[category]['y_train'],\n",
    "                          param_grid=grid,\n",
    "                          n_jobs=-2,\n",
    "                          cv=5)\n",
    "    # Serialización del mejor modelo\n",
    "    model_reg.to_pickle(car_category=category)\n",
    "    print('\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos y evaluamos los modelos serializados \n",
    "# (muestra de lo que hace la función 'metrics_pickled_mlmodels')\n",
    "pickle_files = [f'{category}_{model.__class__.__name__.lower()}.sav' for model in model_list]\n",
    "\n",
    "for pickle_model in pickle_files:\n",
    "    # Importamos mejor modelo\n",
    "    best_model = MLModel.from_pickle(f'best_models/{pickle_model}')\n",
    "    # Métricas mejor modelo\n",
    "    print(pickle_model[:-4])\n",
    "    print(best_model.train_val_metrics(samples[category]['X_train'], \n",
    "                                      samples[category]['y_train'], \n",
    "                                      samples[category]['X_val'], \n",
    "                                      samples[category]['y_val']))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Modelos Multipurpose Passenger Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la categoría de vehículo a modelar\n",
    "category = 'mpp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Entrenamos, ajustamos hiperparámetros y serializamos modelos\n",
    "fn.train_mlmodels(model_list, grid_list, samples, category)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos y evaluamos los modelos serializados\n",
    "fn.metrics_pickled_mlmodels(model_list, samples, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 Modelos Multipurpose Passenger Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la categoría de vehículo a modelar\n",
    "category = 'trk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Entrenamos, ajustamos hiperparámetros y serializamos modelos\n",
    "fn.train_mlmodels(model_list, grid_list, samples, category)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos y evaluamos los modelos serializados\n",
    "fn.metrics_pickled_mlmodels(model_list, samples, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusión entrenamiento y evaluación modelos por categorías:\n",
    "* Se observa que al igual con el modelo único, los modelos no paramétricos superan en resultados a los modelos paramétricos, siendo `lightgbm`  marginalmente el mejor entre los 4 modelos (evaluando métrica de MAE en validación y su diferencia con respecto a la muestra de entrenamiento).\n",
    "* Se observa en términos generales resultados similares entre las muestras, con un mínimo r2 en muestra de prueba .82 en la categoría `Passenger` y un máximo de .89 en la categoría `Multipurpose Passenger`.\n",
    "\n",
    "Para poder decidir con que tipo de modelo, único o múltiple, se decide utilizar, se evaluará su rendimiento en la muestra de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Evaluación con muestra de Prueba (Hold-out sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos nuestro mejor modelo en la muestra de prueba\n",
    "{key: value for key, value in lgb_best.metrics(X_test, y_test).items() if key != 'r2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los mejores modelos\n",
    "psg_best = MLModel.from_pickle('best_models/psg_lgbmregressor.sav')\n",
    "mpp_best = MLModel.from_pickle('best_models/mpp_lgbmregressor.sav')\n",
    "trk_best = MLModel.from_pickle('best_models/trk_lgbmregressor.sav')\n",
    "# Diccionario con mejores modelos\n",
    "car_models = {'psg': psg_best, 'mpp': mpp_best, 'trk': trk_best}\n",
    "\n",
    "for category, model in car_models.items():\n",
    "    \n",
    "    metrics = model.metrics(samples[category]['X_test'], samples[category]['y_test'])\n",
    "    # Evaluamos en la muestra de validación\n",
    "    print(f'{category}_{model.best_model.__class__.__name__.lower()}')\n",
    "    print({key: value for key, value in metrics.items() if key != 'r2'})\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los resultados en las métricas de los modelos en la muestra de prueba, se pueden observar resultados similares a los obtenidos en la muestra de entrenamiento y validación. En el caso del modelo único, el MAE es practiamente el mismo, manteniendose la distancia con respecto al RSME.\n",
    "\n",
    "Por su parte, la modelación múltiple presenta resultados positivos en las catogorías de 'psg', 'mpp' y 'trk', siendo muy acotadas las diferencias en el MAE y r2 de la muestra de validación y de prueba, siendo la diferencia con RSME igualmente similar. \n",
    "\n",
    "Cómo se observa en los resultados de las métricas, la diferencia entre el MAE y el RSME es una constante tanto para las muestra de prueba y validación, especialmente para el caso de 'trk'. Esta situación daría indicios de que el posiblemente modelo está subestimando el precio de vehículos, especialmente el de los segmentos más caros. Para corroborar esta hipótesis, observaremos la distribución de los precios en las muestras de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico de boxplot para observar la distribución de los precios por muestra\n",
    "box_list = []\n",
    "car_types = ['psg', 'mpp', 'trk']\n",
    "for category in car_types:\n",
    "    box_list += [samples[category]['y_test']]\n",
    "\n",
    "plt.boxplot(box_list, labels=car_types, vert=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En conclusión:\n",
    "* Se observa que las ditribuciones de las muestras de validación siguen presentando un número de casos posibles de denominar como 'outliers', sinedo especialmente drámatico el caso de la muestra de 'psg'.\n",
    "* Por lo tanto, sea modelo único o múltiple, se observan las limitaciones de la modelación, en los casos de vehículos de alta gama, cuyos precios superarían ciertos rangos, dependiendo del tipo de vehículo.\n",
    "* A pesar de esta limitación, los rendimientos por separados muestran un marginalmente un mejor desempeño en datos no observados por el modelo al entrenarse, por lo que se prefería continuar con los modelos múltiples por tipo de vehículo para desarrollar la solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Análisis de Distribución de Errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generación de lista con bases de Prueba con atributos.\n",
    "X_test_list=[X_test,\n",
    "            samples[\"psg\"][\"X_test\"],\n",
    "            samples[\"mpp\"][\"X_test\"],\n",
    "            samples[\"trk\"][\"X_test\"]]\n",
    "# generación de lista con bases de Prueba con vector objetivo.\n",
    "y_test_list=[y_test,\n",
    "            samples[\"psg\"][\"y_test\"],\n",
    "            samples[\"mpp\"][\"y_test\"],\n",
    "            samples[\"trk\"][\"y_test\"]]\n",
    "# generación de lista con modelos.\n",
    "model_list=[lgb_best.best_model, psg_best.best_model,\n",
    "            mpp_best.best_model,trk_best.best_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ Plot\n",
    "fn.qq_plot(model_list,X_test_list, y_test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comentarios__:\n",
    "De manera adicional a las métricas de RMSE y MAE, proponemos observar la conducta de los modelos con un QQ plot. Este gráfico comparara la distribución de los errores (residuos) con la distribución normal. Los gráficos muestran que los errores de los modelos tienen buen comportamiento entre los cuartiles -4 y 2. La situación cambia con los cuartiles 2 y 4. Nuestros modelos fallan en mayor medida para autos de valores altos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Feature importaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance modelo de pasageros psg\n",
    "plt.rcParams['figure.figsize'] = (3.3, 5)\n",
    "fn.grafico_importancia(model_list[1],X_test_list[1].columns)\n",
    "plt.xlabel(\"Importancia relativa\");\n",
    "plt.ylabel('Atributos');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance modelo de multipropósiro (mpp)\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "fn.grafico_importancia(model_list[2],X_test_list[2].columns)\n",
    "plt.xlabel(\"Importancia relativa\");\n",
    "plt.ylabel('Atributos');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance modelo de truk (trk)\n",
    "plt.rcParams['figure.figsize'] = (5.5, 5)\n",
    "fn.grafico_importancia(model_list[3],X_test_list[3].columns)\n",
    "plt.xlabel(\"Importancia relativa\");\n",
    "plt.ylabel('Atributos');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comentarios__:\n",
    "Para los tres tipos de vehículos los atributos más importantes son Mileage (kilométrajes), Displacement (cilindrada) y use_age (antiguedad del vehículo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Pipeline y Serialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializamos modelo único\n",
    "# Generamos el objeto pipeline con nuestro mejor modelo y transformadores entrenados\n",
    "pipeline = lgb_best.to_pipeline(df_prep.transformers, \n",
    "                                df_prep.df_ct.drop(columns=['Price', 'sample']))\n",
    "# Serializamos el pipeline\n",
    "pickle.dump(pipeline, open('best_models/pipeline_allcars.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serializamos modelo múltiple\n",
    "for category, model in car_models.items():\n",
    "    \n",
    "    # Generamos el objeto pipeline con nuestro mejor modelo y transformadores entrenados\n",
    "    pipe = model.to_pipeline(samples[category]['transformers'], \n",
    "                             samples[category]['df_ct'].drop(columns=['Price', 'sample']))\n",
    "    # Serializamos el pipeline\n",
    "    pickle.dump(pipe, open(f'best_models/pipeline_{category}.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Política de Recomendación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo definido un modelo que posbilite la estimación de un __precio de mercado__, para poder ofrecer una recomendación a través de la aplicación desarrollada debemos ofrecer una evaluación de posibles alternativas de compras. Actualmente podemos calcular el potencial margen de una oferta a través de la siguiente formula:\n",
    " \n",
    "$$ m_{usd} = P_{estimado} - P_{ofertado}$$  \n",
    "Siendo el $P_{estimado}$ el precio estimado por nuestro modelo y $P_{ofertado}$ el precio ofertado para poder adquirir el vehículo.  \n",
    "Por otro lado, podemos establecer la misma métrica en términos porcentuales:\n",
    "\n",
    "$$ m_{pct} = \\frac{P_{estimado} - P_{ofertado}} {P_{estimado}}$$ \n",
    "\n",
    "Lo cual nos permite establecer una polítca de compra en base a términos porcentuales de margene requerido para considerar como una buena compra. Cómo el mercado automotriz es bien competitivo, especialmente en Estados Unidos, podemos definir que una compra con al menos un 8% de margen sea considerado como una compra recomendada, lo que podemos expresar con la siguiente formula:  \n",
    "\n",
    "$$ m_{pct} - 0.08 > 0 => {Recomendado-comprar}$$\n",
    "\n",
    "Pero cómo cualquier modelo de estimación de precios, nuestro modelo no es infalible. Cómo se mostró en la sección anterior, dependiendo del vehículo, este puede fallar en mayor o menor envergadura. Con la información utilizada para entrenar el modelo, podemos calcular el error en términos porcentuales para cada observación de esta muestra. De este cálculo podemos, generar la media de este error por modelo de vehículo, que es una variable que engloba muchos atributos relevantes del vehículo (ej: marca, tipo chasís, etc.) y por lo tanto de importancia para el precio, y por lo tanto generar un proxy estimativo del error que generaría el modelo ante una nueva observación. Dicho error histórico se puede representar de la siguiente forma:  \n",
    "\n",
    "Error Histórico Promedio para Modelo j:   \n",
    "\n",
    "$$ e_j = \\frac {1}{n} \\sum_{i=1}^{i\\in j} \\frac{P_{hist-estimado}-P_{hist-ofrecido}} {P_{hist-estimado}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la base para calcular los errores \n",
    "df_aux = df.loc[:, select_vars + ['sgt_Model']].dropna().reset_index(drop=True)\n",
    "df_aux['Marca'] = df_aux['sgt_Make']\n",
    "aux_dict = {value: key for key, value in car_dict.items()}\n",
    "df_aux['ml_model'] = df_aux['sgt_VehicleType'].map(aux_dict)\n",
    "df_aux = df_aux.drop(columns='sgt_VehicleType').rename(columns={'sgt_Model': 'Modelo'})\n",
    "# Instanciamos la clase para preprocesamiento\n",
    "prep_aux = PrepML(df_aux)\n",
    "# Eliminación de Outliers\n",
    "prep_aux.remove_outliers(['Price', 'use_Mileage', 'use_Age', 'feat_DisplacementCC', \n",
    "                         'feat_EngineCylinders'], iqr_multiplier=1.5,\n",
    "                          print_diff=False)\n",
    "# Realizamos OneHot Encoder a las columnas categóricas seleccionadas\n",
    "prep_aux.one_hot_encoder(['sgt_BodyClass', 'sgt_Make'],\n",
    "                        drop_first=True)\n",
    "# Estandarizamos variables continuas seleccionadas\n",
    "prep_aux.standard_scaler(['use_Mileage', 'use_Age', 'feat_DisplacementCC', \n",
    "                         'feat_EngineCylinders'])\n",
    "# Eliminamos la variable que separaba las muestras\n",
    "df_aux = prep_aux.df.drop(columns='sample')\n",
    "# Cambio de tipo de dato para 'ml_model'\n",
    "ml_type = CategoricalDtype(categories=['psg', 'mpp', 'trk'], ordered=True)\n",
    "df_aux = df_aux.astype({'ml_model': ml_type}).sort_values(by='ml_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos las predicciones por categoría de vehículo\n",
    "y_hat = []\n",
    "for category, model in car_models.items(): \n",
    "    y_hat += list(model.best_model.predict(df_aux[df_aux['ml_model'] == category]\\\n",
    "                                               .loc[:, samples[category]['X_train'].columns]\n",
    "                                          ))\n",
    "# Redondeamos y pasamos a integer las predicciones\n",
    "y_hat = [int(round(i, 0)) for i in y_hat] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las variables 'y_hat' y 'error'\n",
    "df_aux['y_hat'] = y_hat\n",
    "df_aux['error'] = (df_aux['y_hat'] - df_aux['Price'])/df_aux['y_hat']\n",
    "df_aux['error'] = df_aux['error'].map(lambda x: round(x, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error Promedio por Marca/Modelo\n",
    "error_df = df_aux.loc[:, ['Marca', 'Modelo', 'Price', 'y_hat', 'error']]\\\n",
    "            .groupby(by=['Marca', 'Modelo'])\\\n",
    "            .agg({'Price': ['mean', 'count'], 'y_hat': 'mean', 'error': 'mean'})\\\n",
    "            .round(2)\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar del cálculo de error por modelo, este puede diferir considerablemente y en distintas direcciones dependiendo del modelo del vehículo, subestimando o sobrestimando el precio de manera importante en ciertos casos. Es por ello que proponemos usar esta error histórico para ajustar el margen generado por el precio ofrecido y el precio estimado, de la siguiente forma:\n",
    "\n",
    "Margen ajustado para oferta i de modelo j de vehículo:  \n",
    "$$ ma_i = m_i - e_j $$\n",
    "\n",
    "Pero si observamos más a fondo el error histórico, nos encontramos con que a pesar de la corrección, la estimación puede ser muy poco acertada, por lo que es necesario generar matices a esta correción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución del error histórico\n",
    "ax = sns.boxplot(error_df['error'])\n",
    "plt.title('Boxplot errores históricos por modelo de vehículo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuartiles y rango intercuartil de boxplot\n",
    "q1 = error_df['error'].quantile(0.25).values[0]\n",
    "q3 = error_df['error'].quantile(0.75).values[0]\n",
    "iqr = q3 - q1\n",
    "print(f'Primer Cuartil: {q1}\\nTercer Cuartil: {q3}')\n",
    "print(f'Bigote Inferior:{round(q1 - iqr*1.5, 2)}\\nBigote Superior:{round(q3 + iqr*1.5, 2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo que para evitar malas recomendaciones, se evitará entregar una recomendación cuyos modelos de vehículos tengan precio de mercado con errores históricos superiores al $0.6$ o inferiores a $-0.72$, dado que aún con la correción, la estimación puede ser muy poco fíable. Bajo el mismo concepto, la recomendación se hará con reservas si, habiendose cumplido las condiciones de margen ajustado mayor a 8%, el error histórico promedio del modelo no se encuentra entre el primer y tercer quintil de la distribución de los errores históricos. Finalmente, a continuación se resume como la política de recomendación se establecería:\n",
    "\n",
    "Para un oferta $i$ de modelo de vehículo $j$ con un margen mínimo desado de 8%:\n",
    "\n",
    "`if` $(e_j <-0.72$ `or` $ e_j > 0.6)$ => `No hay Recomendación`   \n",
    "`elif` $(m_i - e_j < 0.08 ) =>$ `No Recomendado para comprar`  \n",
    "`elif` $(-0.23 <= e_j <= 0.1)$ `&` $(m_i - e_j >= 0.08) =>$ `Recomendado comprar con seguridad`  \n",
    "`elif` $(e_j <-0.23$ `or` $ e_j > 0.1$) `&` ($m_i - e_j >= 0.08) =>$ `Recomendado comprar con reservas`  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Conclusión\n",
    "\n",
    "Para predecir un Precio de Mercado de un vehículo usado a través de sus atributos propios o de uso, conluímos que utilizar una serie de modelos por tipo de vehículo (de pasajeros, multiproposito o camión) genera mejores resultados en la muestra de prueba (r2 promedio .85) y de validación (r2 promedio de .7 sin remover outliers).\n",
    "\n",
    "Como lo son vehículos de pasajeros, multiproposito y camionetas, esto porque sus carasterísticas técnicas y precios son bastante diferentes y nos obligan a buscar resultados mas precisos gracias a esta segmentación, respecto a la precisión al momento de predecir vehículos de un mayor valor, o también denominados de alta gamma, nuestro modelo tiende a aumentar el error en estos casos, esto porque la mayor parte de los precios en la data de entrenamiento se situan entre los 10.000 y 37.000 USD, por lo que para los casos que están por sobre el promedio se genera lo que conocemos como underfitting y nuestro modelo no logra predecir con exactitud el precio requerido.\n",
    "\n",
    "Si bien una de las alternativas posibles y recomendadas al igual que se hizo con las tipologias de vehículos, sería generar nuevos modelos para gammas bajas y gammas altas de vehículos, en esta ocación esa alternativa no es viable dado que contamos con un numero de datos para los casos de vehículos caros que no logra la cantidad suficiente de muestra, que nos permita realizar un entrenamiento del modelo para esta tipología. Por ende para lograr esa solución se deben buscar nuevos datos que se asemejen a los de alta gamma.\n",
    "\n",
    "Cabe destacar que la función principal del modelo a traves de la aplicación web es generar una recomendación en función del precio estimado para las características técnicas y de uso de cada vehículo, lo cual se cumple y logra de manera bastante eficiente, pero es importante tener en consideración que existen factores estéticos, técnicos, de demanda del modelo y rotación de este, y también relacionados al cuidado del vehículo (considerando que son usados), que se deben tener presente al momento de definir si un determinado vehículo es o no una buen negocio para la automotora."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
