{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación \n",
    "### Equipo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros generales del notebook\n",
    "ruta_bases = 'bases/'\n",
    "sample_size =  2000\n",
    "cv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación ambiente AWS SageMaker\n",
    "#!pip install --upgrade pip\n",
    "#!pip install xgboost\n",
    "#!pip install lightgbm\n",
    "#!pip install -U scikit_learn\n",
    "#!pip install -U pandas\n",
    "#!pip install -U matplotlib\n",
    "#!pip install -U seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import funciones as fn\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from ml_classes import PrepML, MLModel\n",
    "from matplotlib.pyplot import rcParams\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import Ridge,SGDRegressor\n",
    "from lib.get_nhtsa_json import get_nhtsa_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros generales para plots\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = 15, 8\n",
    "plt.style.use('ggplot')\n",
    "# Semilla pseudo-aleatoria\n",
    "rd_seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Obtener la información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta es una demostración del proceso realizado por `get_features.py` para poder obtener información relacionada con el `Vin` de los vehículos a través de una API. El proceso consite en los siguientes pasos:\n",
    "* 1.- Extraer todos los `Vin` de la base completa `true_car_listings.csv`.\n",
    "* 2.- Requerir a través de la Api 'chunks' de 50 registros por cada petición.\n",
    "* 3.- Guardar en la memoria el json en formato texto, agregando 50 registros por cada iteración.\n",
    "* 4.- Una vez completada las iteraciones guardar en formato json todos los registros requeridos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8: 0.9s\n"
     ]
    }
   ],
   "source": [
    "# Requerimos todos los 'Vin'    \n",
    "all_vins = pd.read_csv(f'{ruta_bases}true_car_listings.csv')['Vin'].to_list()\n",
    "# Parámetros de muestra\n",
    "start = 8\n",
    "end = 8\n",
    "\n",
    "json_text = '['\n",
    "for i in range(start, end+1):\n",
    "    # Generar requerimiento con 50 registros Vin\n",
    "    vin_list = all_vins[50 * (i - 1):50 * i]\n",
    "    json_text += get_nhtsa_json(vin_list, i)\n",
    "\n",
    "# Cerrar lista de Json\n",
    "json_text = json_text[:-2] + ']'\n",
    "# Exportar resultados a archivo json\n",
    "with open(f'api_test/data_{start}_{end}.json', 'w') as json_file:\n",
    "    json_file.write(json_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paralelamente, en base a una muestra de la base total, se definió el primer filtro de variables requeridas a través la API: que tengan menos del 10% de datos perdidos, las cuales se presentan a continaución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['AirBagLocFront', 'BodyClass', 'BusFloorConfigType', 'BusType',\n",
    "       'CustomMotorcycleType', 'DisplacementCC', 'DisplacementCI',\n",
    "       'DisplacementL', 'Doors', 'EngineCylinders', 'EngineHP', 'EngineKW',\n",
    "       'ErrorCode', 'ErrorText', 'FuelTypePrimary', 'Make', 'Manufacturer',\n",
    "       'ManufacturerId', 'Model', 'ModelYear', 'MotorcycleChassisType',\n",
    "       'MotorcycleSuspensionType', 'PlantCity', 'PlantCountry', 'TPMS',\n",
    "       'TrailerBodyType', 'TrailerType', 'VIN', 'VehicleType']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estas columnas seleccionadas, se procede a importar los archivos json (varios en el proceso original) para luego mapearlos para retraer solo aquellas columnas, creando un DataFrame con ellas y luego exportarlas en un csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_test/data_8_8.json\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "29 columns passed, passed data had 0 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    499\u001b[0m         result = _convert_object_array(\n\u001b[0;32m--> 500\u001b[0;31m             \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[0;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0;34m\"{col:d} columns passed, passed data had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                 \u001b[0;34m\"{con} columns\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m             )\n",
      "\u001b[0;31mAssertionError\u001b[0m: 29 columns passed, passed data had 0 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c0148a44bcad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Creación y exortación de DataFrame con features extraídos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m data_json = pd.DataFrame(data=json_list,\n\u001b[0;32m---> 17\u001b[0;31m                          columns=cols)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdata_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'api_test/data_api.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# columns if columns is not None else []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         return _list_of_dict_to_arrays(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    501\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 29 columns passed, passed data had 0 columns"
     ]
    }
   ],
   "source": [
    "# Importación de archivo json\n",
    "filenames = glob.glob('api_test/*.json')\n",
    "json_list = []\n",
    "\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    with open(filename, 'r') as file:\n",
    "        # Mapeamos considerando solo las columnas seleccionadas\n",
    "        data = list(map(fn.get_info, \n",
    "                        json.loads(file.read())\n",
    "                       )\n",
    "                   )\n",
    "    json_list += data\n",
    "\n",
    "# Creación y exortación de DataFrame con features extraídos\n",
    "data_json = pd.DataFrame(data=json_list,\n",
    "                         columns=cols)\n",
    "data_json.to_csv('api_test/data_api.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Creación del Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Bases Originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Train: (639145, 8)\n",
      "Base Test: (212977, 8)\n"
     ]
    }
   ],
   "source": [
    "# Importación de las bases para muestras de entrenamiento y prueba\n",
    "df_train = pd.read_csv(f'{ruta_bases}true_cars_train.csv',\n",
    "                       delimiter=\";\")\n",
    "df_test = pd.read_csv(f'{ruta_bases}true_cars_test.csv',\n",
    "                      delimiter=\";\")\n",
    "# Dimensiones de las bases\n",
    "print(f'Base Train: {df_train.shape}\\nBase Test: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 639145 entries, 0 to 639144\n",
      "Data columns (total 8 columns):\n",
      "Price      639145 non-null int64\n",
      "Year       639145 non-null int64\n",
      "Mileage    639145 non-null int64\n",
      "City       639145 non-null object\n",
      "State      639145 non-null object\n",
      "Vin        639145 non-null object\n",
      "Make       639145 non-null object\n",
      "Model      639145 non-null object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 39.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Información general de muestra de entrenamiento\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de atributo 'sample'\n",
    "df_train['sample'] = 'train'\n",
    "df_test['sample'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Data: (852122, 9)\n"
     ]
    }
   ],
   "source": [
    "# Unión de ambas bases\n",
    "df_data = pd.concat([df_train, df_test])\n",
    "print(f'Base Data: {df_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Base API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base API: (846562, 29)\n"
     ]
    }
   ],
   "source": [
    "# Importación de la base extraída por el requerimiento a la api\n",
    "df_api = pd.read_csv(f'{ruta_bases}api_features.csv').drop(columns='Unnamed: 0')\n",
    "print(f'Base API: {df_api.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 846562 entries, 0 to 846561\n",
      "Data columns (total 29 columns):\n",
      "AirBagLocFront              797265 non-null object\n",
      "BodyClass                   845535 non-null object\n",
      "BusFloorConfigType          843524 non-null object\n",
      "BusType                     843524 non-null object\n",
      "CustomMotorcycleType        846525 non-null object\n",
      "DisplacementCC              839096 non-null float64\n",
      "DisplacementCI              839096 non-null float64\n",
      "DisplacementL               839096 non-null float64\n",
      "Doors                       739918 non-null float64\n",
      "EngineCylinders             735744 non-null object\n",
      "EngineHP                    380764 non-null object\n",
      "EngineKW                    380764 non-null object\n",
      "ErrorCode                   846550 non-null object\n",
      "ErrorText                   846550 non-null object\n",
      "FuelTypePrimary             789859 non-null object\n",
      "Make                        846525 non-null object\n",
      "Manufacturer                846525 non-null object\n",
      "ManufacturerId              846525 non-null float64\n",
      "Model                       846044 non-null object\n",
      "ModelYear                   846522 non-null float64\n",
      "MotorcycleChassisType       846525 non-null object\n",
      "MotorcycleSuspensionType    846525 non-null object\n",
      "PlantCity                   694188 non-null object\n",
      "PlantCountry                798155 non-null object\n",
      "TPMS                        674177 non-null object\n",
      "TrailerBodyType             846524 non-null object\n",
      "TrailerType                 846524 non-null object\n",
      "VIN                         846550 non-null object\n",
      "VehicleType                 846525 non-null object\n",
      "dtypes: float64(6), object(23)\n",
      "memory usage: 187.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_api.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas con solo valores \"Not Applicable\" \n",
    "notapp_series = df_api\\\n",
    "                    .isin(['Not Applicable'])\\\n",
    "                    .sum()\n",
    "cols2drop = list(notapp_series[notapp_series > 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base API: (846562, 22)\n"
     ]
    }
   ],
   "source": [
    "# Borrar aquellas columnas \n",
    "df_api = df_api.drop(columns=cols2drop)\n",
    "print(f'Base API: {df_api.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api=df_api.rename(columns={\"AirBagLocFront\":\"d_AirBagLocFront\",\n",
    "                        \"BodyClass\":\"d_BodyClass\",\n",
    "                        \"DisplacementCC\":\"d_DisplacementCC\",\n",
    "                        \"DisplacementCI\":\"d_DisplacementCI\",\n",
    "                        \"DisplacementL\":\"d_DisplacementL\",\n",
    "                        \"Doors\":\"d_Doors\",\n",
    "                        \"EngineCylinders\":\"d_EngineCylinders\",\n",
    "                        \"EngineHP\":\"d_EngineHP\",\n",
    "                        \"EngineKW\":\"d_EngineKW\",\n",
    "                        \"ErrorCode\":\"d_ErrorCode\",\n",
    "                        \"ErrorText\":\"d_ErrorText\",\n",
    "                        \"FuelTypePrimary\":\"d_FuelTypePrimary\",\n",
    "                        \"Make\":\"d_Make\",\n",
    "                        \"Manufacturer\":\"d_Manufacturer\",\n",
    "                        \"ManufacturerId\":\"d_ManufacturerId\",\n",
    "                        \"Model\":\"d_Model\",\n",
    "                        \"ModelYear\":\"d_ModelYear\",\n",
    "                        \"PlantCity\":\"d_PlantCity\",\n",
    "                        \"PlantCountry\":\"d_PlantCountry\",\n",
    "                        \"TPMS\":\"d_TPMS\",\n",
    "                        \"VIN\":\"Vin\",\n",
    "                        \"VehicleType\":\"d_VehicleType\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Unión de Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: (846644, 30)\n"
     ]
    }
   ],
   "source": [
    "# Unión de bases\n",
    "df = pd.merge(left=df_data, \n",
    "              right=df_api, \n",
    "              how='inner',\n",
    "              on='Vin')\n",
    "# Dimensiones de la base\n",
    "print(f'Dataset: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 846644 entries, 0 to 846643\n",
      "Data columns (total 30 columns):\n",
      "Price                846644 non-null int64\n",
      "Year                 846644 non-null int64\n",
      "Mileage              846644 non-null int64\n",
      "City                 846644 non-null object\n",
      "State                846644 non-null object\n",
      "Vin                  846644 non-null object\n",
      "Make                 846644 non-null object\n",
      "Model                846644 non-null object\n",
      "sample               846644 non-null object\n",
      "d_AirBagLocFront     797359 non-null object\n",
      "d_BodyClass          845629 non-null object\n",
      "d_DisplacementCC     839190 non-null float64\n",
      "d_DisplacementCI     839190 non-null float64\n",
      "d_DisplacementL      839190 non-null float64\n",
      "d_Doors              740010 non-null float64\n",
      "d_EngineCylinders    735838 non-null object\n",
      "d_EngineHP           380796 non-null object\n",
      "d_EngineKW           380796 non-null object\n",
      "d_ErrorCode          846644 non-null object\n",
      "d_ErrorText          846644 non-null object\n",
      "d_FuelTypePrimary    789951 non-null object\n",
      "d_Make               846619 non-null object\n",
      "d_Manufacturer       846619 non-null object\n",
      "d_ManufacturerId     846619 non-null float64\n",
      "d_Model              846138 non-null object\n",
      "d_ModelYear          846616 non-null float64\n",
      "d_PlantCity          694282 non-null object\n",
      "d_PlantCountry       798249 non-null object\n",
      "d_TPMS               674263 non-null object\n",
      "d_VehicleType        846619 non-null object\n",
      "dtypes: float64(6), int64(3), object(21)\n",
      "memory usage: 200.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Información general del dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Limpieza del Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 ErrorText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna ErrorText, nos entrega información relevante respecto a los datos obtenidos desde la API y su relación con el número único VIN. A partir de ella, se decide mantener solo aquellos datos que se obtuvieron de manera correcta (845778 de 846644). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1 - Check Digit (9th position) does not calculate properly; 11 - Incorrect Model Year, decoded data may not be accurate                                                                                                                                        1\n",
       "1 - Check Digit (9th position) does not calculate properly; 4 - VIN corrected, error in one position only (indicated by ! in Suggested VIN), multiple matches found                                                                                            1\n",
       "6 - Incomplete VIN; 7 - Manufacturer is not registered with NHTSA for sale or importation in the U.S. for use on U.S roads; Please contact the manufacturer directly for more information; 11 - Incorrect Model Year, decoded data may not be accurate         1\n",
       "1 - Check Digit (9th position) does not calculate properly; 5 - VIN has errors in few positions; 14 - Unable to provide information for all the characters in the VIN.                                                                                         2\n",
       "1 - Check Digit (9th position) does not calculate properly; 2 - VIN corrected, error in one position; 14 - Unable to provide information for all the characters in the VIN.                                                                                    2\n",
       "11 - Incorrect Model Year, decoded data may not be accurate; 14 - Unable to provide information for all the characters in the VIN.                                                                                                                             2\n",
       "1 - Check Digit (9th position) does not calculate properly; 4 - VIN corrected, error in one position only (indicated by ! in Suggested VIN), multiple matches found; 14 - Unable to provide information for all the characters in the VIN.                     4\n",
       "1 - Check Digit (9th position) does not calculate properly; 14 - Unable to provide information for all the characters in the VIN.                                                                                                                              4\n",
       "7 - Manufacturer is not registered with NHTSA for sale or importation in the U.S. for use on U.S roads; Please contact the manufacturer directly for more information                                                                                          7\n",
       "4 - VIN corrected, error in one position only (indicated by ! in Suggested VIN), multiple matches found                                                                                                                                                        8\n",
       "1 - Check Digit (9th position) does not calculate properly; 3 - VIN corrected, error in one position (assuming Check Digit is correct); 14 - Unable to provide information for all the characters in the VIN.                                                 10\n",
       "1 - Check Digit (9th position) does not calculate properly; 7 - Manufacturer is not registered with NHTSA for sale or importation in the U.S. for use on U.S roads; Please contact the manufacturer directly for more information                             17\n",
       "2 - VIN corrected, error in one position; 14 - Unable to provide information for all the characters in the VIN.                                                                                                                                               26\n",
       "8 - No detailed data available currently                                                                                                                                                                                                                      37\n",
       "5 - VIN has errors in few positions; 14 - Unable to provide information for all the characters in the VIN.                                                                                                                                                    84\n",
       "4 - VIN corrected, error in one position only (indicated by ! in Suggested VIN), multiple matches found; 14 - Unable to provide information for all the characters in the VIN.                                                                               153\n",
       "3 - VIN corrected, error in one position (assuming Check Digit is correct); 14 - Unable to provide information for all the characters in the VIN.                                                                                                            181\n",
       "1 - Check Digit (9th position) does not calculate properly                                                                                                                                                                                                   326\n",
       "0 - VIN decoded clean. Check Digit (9th position) is correct; 14 - Unable to provide information for all the characters in the VIN.                                                                                                                         4395\n",
       "0 - VIN decoded clean. Check Digit (9th position) is correct                                                                                                                                                                                              841383\n",
       "Name: d_ErrorText, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# revisamos la columna ErrorText, que entrega información respecto errores en la extracción de los datos\n",
    "df['d_ErrorText'].value_counts().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se mantienen solo los datos extraídos correctamente\n",
    "df = df[(df['d_ErrorText'] == '0 - VIN decoded clean. Check Digit (9th position) is correct') |\n",
    "       (df['d_ErrorText'] == '0 - VIN decoded clean. Check Digit (9th position) is correct; 14 - Unable to provide information for all the characters in the VIN.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se eliminan las columnas de error que ya utilizamos\n",
    "df = df.drop(columns=[\"d_ErrorCode\",\"d_ErrorText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de atributo\n",
    "df[\"d_EngineCylinders\"] = df[\"d_EngineCylinders\"].map(lambda x: float(str(x)\\\n",
    "                                                                   .replace('12, 8', '12')\\\n",
    "                                                                   .replace('8, 12', '8'))\n",
    "                                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Nulos, datos duplicados y columnas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_AirBagLocFront     0.06\n",
       "d_DisplacementCC     0.01\n",
       "d_DisplacementCI     0.01\n",
       "d_DisplacementL      0.01\n",
       "d_Doors              0.13\n",
       "d_EngineCylinders    0.13\n",
       "d_EngineHP           0.55\n",
       "d_EngineKW           0.55\n",
       "d_FuelTypePrimary    0.07\n",
       "d_PlantCity          0.18\n",
       "d_PlantCountry       0.06\n",
       "d_TPMS               0.20\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Datos nulos\n",
    "#Mediante \"isnull()\", sum() y shape() identificamos los atributos con datos nulos y su procentaje relativo.\n",
    "null = round(df.isnull().sum()/df.shape[0],2) \n",
    "null[null>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas con más de un 15% de datos perdidos\n",
    "null_series = df_api\\\n",
    "                .isnull()\\\n",
    "                .sum()\\\n",
    "                /df_api.shape[0] \n",
    "df = df.drop(columns=list(null_series[null_series > .15].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 24)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Datos duplicados\n",
    "#Observamos la cantidad de registros duplicados en el df.\n",
    "duplicate_rows_df = df[df.duplicated()]\n",
    "duplicate_rows_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los registros duplicados\n",
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.839245\n",
       "True     0.160755\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columnas duplicadas\n",
    "# Chequemos si la columna Model, (data set de la academia) y la columna d_Model (data de la API) son iguales.\n",
    "(df.Model==df.d_Model).value_counts(\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>d_Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILX5-Speed</td>\n",
       "      <td>ILX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ILX5-Speed</td>\n",
       "      <td>ILX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ILXAutomatic</td>\n",
       "      <td>ILX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TSXAutomatic</td>\n",
       "      <td>TSX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TSX5-Speed</td>\n",
       "      <td>TSX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model d_Model\n",
       "0    ILX5-Speed     ILX\n",
       "1    ILX5-Speed     ILX\n",
       "2  ILXAutomatic     ILX\n",
       "3  TSXAutomatic     TSX\n",
       "4    TSX5-Speed     TSX"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vemos los primeros 5 registros de model y d_model.\n",
    "df[['Model', 'd_Model']] .head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.905707\n",
       "True     0.094293\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chequemos si la columna Make, (data set de la academia) y la columna d_Make (data de la API) son iguales.\n",
    "(df.Make==df.d_Make).value_counts(\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AM', 'Acura', 'Alfa', 'Aston', 'Audi', 'BMW', 'Bentley', 'Buick',\n",
       "       'Cadillac', 'Chevrolet', 'Chrysler', 'Dodge', 'FIAT', 'Ferrari',\n",
       "       'Fisker', 'Ford', 'Freightliner', 'GMC', 'Genesis', 'Geo', 'Honda',\n",
       "       'Hyundai', 'INFINITI', 'Isuzu', 'Jaguar', 'Jeep', 'Kia',\n",
       "       'Lamborghini', 'Land', 'Lexus', 'Lincoln', 'Lotus', 'MINI',\n",
       "       'Maserati', 'Maybach', 'Mazda', 'McLaren', 'Mercedes-Benz',\n",
       "       'Mercury', 'Mitsubishi', 'Nissan', 'Oldsmobile', 'Plymouth',\n",
       "       'Pontiac', 'Porsche', 'Ram', 'Rolls-Royce', 'Saab', 'Saturn',\n",
       "       'Scion', 'Subaru', 'Suzuki', 'Tesla', 'Toyota', 'Volkswagen',\n",
       "       'Volvo', 'smart'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores unicos columna make.\n",
    "np.unique(df.Make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ACURA', 'ALFA ROMEO', 'ASTON MARTIN', 'AUDI', 'BENTLEY', 'BMW',\n",
       "       'BUICK', 'CADILLAC', 'CHEVROLET', 'CHRYSLER', 'DODGE',\n",
       "       'DODGE, CHRYSLER, VOLKSWAGEN, JEEP, FIAT, RAM, LANCIA', 'FERRARI',\n",
       "       'FIAT', 'FISKER AUTOMOTIVE', 'FORD', 'FREIGHTLINER', 'GENESIS',\n",
       "       'GMC', 'GMC, PONTIAC, GEO', 'HONDA', 'HUMMER ', 'HYUNDAI',\n",
       "       'HYUNDAI, KIA', 'INFINITI', 'ISUZU', 'JAGUAR', 'JEEP', 'KIA',\n",
       "       'LAMBORGHINI', 'LAND ROVER', 'LEXUS', 'LINCOLN', 'LOTUS',\n",
       "       'MASERATI', 'MAYBACH', 'MAZDA', 'MCLAREN', 'MERCEDES-BENZ',\n",
       "       'MERCEDES-BENZ, MAYBACH', 'MERCURY', 'MINI', 'MITSUBISHI',\n",
       "       'NISSAN', 'NISSAN, INFINITI', 'OLDSMOBILE', 'PLYMOUTH', 'PONTIAC',\n",
       "       'PORSCHE', 'RAM', 'ROLLS ROYCE', 'SAAB', 'SATURN', 'SMART',\n",
       "       'SPRINTER (DODGE OR FREIGHTLINER)', 'SUBARU', 'SUZUKI', 'TESLA',\n",
       "       'TOYOTA', 'VOLKSWAGEN', 'VOLVO'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores unicos columna d_make.\n",
    "np.unique(df.d_Make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.999987\n",
       "False    0.000013\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.Year == df.d_ModelYear).value_counts(\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminación columnas duplicadas provenientes de las API,\n",
    "df = df.drop(columns=['d_Make',\"d_Model\",\"d_ModelYear\", 'd_ManufacturerId',\n",
    "                      'd_DisplacementCI', 'd_DisplacementL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de variables no informativas\n",
    "df = df.drop(columns=['Vin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comentarios:\n",
    "\n",
    "Para asegurar la calidad de los registros se revisan los valores nulos y duplicados, en donde podemos observar que los porcentajes de valores nulos por atributo son bastante bajos en general, con excepción de d_engineHP, d_EngineKW y d_TPMS, con valores de 0.55, 0.55 y 0.2 respectivamente. Estas tres variables son candidatas a no ser consideradas en el modelamiento de datos. \n",
    "\n",
    "Respecto a los registros duplicados, se detectan 161 registros bajo esta condición, por lo que se procede a su eliminacion.\n",
    "\n",
    "Se decide eliminar las columnas duplicadas, d_Make y d_Model provenientes de la API. En el caso de d_Make, los nombres de las marcas no vienen normalizados, en cambio en Make si. Finalmente, la columna d_Model viene con menos información asociada al modelo respecto a la columna Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 845617 entries, 0 to 846643\n",
      "Data columns (total 17 columns):\n",
      "Price                845617 non-null int64\n",
      "Year                 845617 non-null int64\n",
      "Mileage              845617 non-null int64\n",
      "City                 845617 non-null object\n",
      "State                845617 non-null object\n",
      "Make                 845617 non-null object\n",
      "Model                845617 non-null object\n",
      "sample               845617 non-null object\n",
      "d_AirBagLocFront     796625 non-null object\n",
      "d_BodyClass          844836 non-null object\n",
      "d_DisplacementCC     838484 non-null float64\n",
      "d_Doors              739282 non-null float64\n",
      "d_EngineCylinders    735176 non-null float64\n",
      "d_FuelTypePrimary    789327 non-null object\n",
      "d_Manufacturer       845617 non-null object\n",
      "d_PlantCountry       797389 non-null object\n",
      "d_VehicleType        845617 non-null object\n",
      "dtypes: float64(3), int64(3), object(11)\n",
      "memory usage: 116.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Inspección general después de limpieza\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Análisis exploratorio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Distribución vector objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## observamos la distribución del precio mediante un histograma y un gráfico de cajas y bigotes.\n",
    "fn.distrbution_graph(df.Price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comentarios:\n",
    "\n",
    "Al observar la distribución del atributo precio (vector objetivo), podemos ver que este es muy variable, teniendo registros con valores muy bajos que parten en los  USD 1.500  como también otros que se disparan del promedio de manera muy marcada alcanzando hasta los USD 499.500. También observamos que la mayoría de los datos se encuetran entre los rangos 0 y 100.000 USD. \n",
    "\n",
    "Lo anterior se puede deber a que dentro de la BDD tenemos diferentes tipos de vehiculos cada uno de estos con sus características propias, es por ello que para las demas variables se decide renombrarlas según dichas caracteristicas.\n",
    "\n",
    "- USE (USE):Atributos relacioados al uso del auto:\n",
    "Year\n",
    "Mileage\n",
    "\n",
    "- SEGMENT (SGT):Atributos asociados al tipo de vehículo:\n",
    "Vehiculetype\n",
    "Bodyclass\n",
    "Make\n",
    "Model\n",
    "Manufacture\n",
    "\n",
    "- FEATURES (FEAT):Atributos asociados las características técnicas del vehículo:\n",
    "Fuel type\n",
    "TPMS\n",
    "Airbag\n",
    "Displacement\n",
    "Doors\n",
    "Engine cilindren\n",
    "\n",
    "- LOCALIZATION (LOC):Atributos asociados a la ubicación del vehículo:\n",
    "state\n",
    "city\n",
    "\n",
    "- FABRICATION(FAB):Atributo de ubicación de la fabricación:\n",
    "Plant city\n",
    "Plant country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se renombran los atributos, según lo indicado anteriormente\n",
    "df=df.rename(columns={\"d_AirBagLocFront\":\"feat_AirBagLocFront\",\n",
    "                        \"d_DisplacementCC\":\"feat_DisplacementCC\",\n",
    "                        \"d_Doors\":\"feat_Doors\",\n",
    "                        \"d_EngineCylinders\":\"feat_EngineCylinders\",\n",
    "                        \"d_EngineHP\":\"feat_EngineHP\",\n",
    "                        \"d_EngineKW\":\"feat_EngineKW\",\n",
    "                        \"d_TPMS\":\"feat_TPMS\",\n",
    "                        \"EngineCylinders\":\"feat_EngineCylinders\",  \n",
    "                        \"d_FuelTypePrimary\":\"feat_FuelTypePrimary\",\n",
    "                        \"d_BodyClass\":\"sgt_BodyClass\",  \n",
    "                        \"d_Manufacturer\":\"sgt_Manufacturer\",\n",
    "                        \"d_VehicleType\":\"sgt_VehicleType\",  \n",
    "                        \"Model\":\"sgt_Model\",\n",
    "                        \"Make\":\"sgt_Make\",\n",
    "                        \"d_PlantCity\":\"fab_PlantCity\",\n",
    "                        \"d_PlantCountry\":\"fab_PlantCountry\",\n",
    "                        \"Year\":\"use_Year\",\n",
    "                        \"Mileage\":\"use_Mileage\",\n",
    "                        \"City\":\"loc_City\",\n",
    "                        \"State\":\"loc_State\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Distribución y relaciones de los atributos con el vector objetivo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Atributos features (feat):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1.1 Matriz de correlación entre atributos \"feat\" númericos u ordinales con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos lista con columnas feat\n",
    "col_names_feat = [col for col in df.columns if 'feat' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos df con columnas feat más Price para hacer la matrix de correlación\"\n",
    "df_feat = df[col_names_feat]\n",
    "df_feat[\"Price\"] = df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos matriz de correlación entre los atributos númericos u ordinales y nuestro vector objetivo precio.\n",
    "f,ax = plt.subplots(figsize=(6, 4))\n",
    "sns.heatmap(df_feat.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1.2 Distribución y relación de los atributos categóricos \"feat con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable \"feat_airbag\"\n",
    "fn.count_box_plot('feat_AirBagLocFront', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable \"feat_Doors\"\n",
    "fn.count_box_plot(\"feat_Doors\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable \"feat_EngineCylinders\"\n",
    "fn.count_box_plot(\"feat_EngineCylinders\",df, 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fn.count_box_plot(\"feat_FuelTypePrimary\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones atributos FEAT:\n",
    "\n",
    "- Los atributos feat_Doors, feat_Airbag, feat_TPMS, feat_FuelType están considerablemente desbalanceadas hacia una categoría. No se recomiendan utilizar estas variables para el modelamiento de datos.\n",
    "- Las tres variables relacionadas al Displacement presentan una correlación de 0.3 con el vector objetivo y se sugiere considerar en el modelamiento. Además, se sugiere considerar una de las tres.\n",
    "- Respecto a la variable feat_EngineCylinders es necesario recodificarla ya que tiene valores con y sin puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Distribución atributos Use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2.1 Matriz de correlación entre atributos \"Use\" númericos u ordinales con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos lista con columnas feat\n",
    "col_names_use = [col for col in df.columns if 'use' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos df con columnas use más Price para hacer la matrix de correlación\"\n",
    "df_use = df[col_names_use]\n",
    "df_use[\"Price\"] = df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generamos matriz de correlación entre los atributos númericos u ordinales y nuestro vector objetivo precio.\n",
    "f,ax = plt.subplots(figsize=(6, 4))\n",
    "sns.heatmap(df_use.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2.2 Distribución y relación de los atributos categóricos \"Use\" con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable use_Mileage\n",
    "fn.distrbution_graph(df.use_Mileage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observamos la distribución de use_Mileage en función del precio, mediante un scatterplot.\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.scatterplot(y=df['Price'], x=df['use_Mileage']);\n",
    "plt.title('Mileage and Price relation ',fontsize=15,color='blue',fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Variable \"Year\"\n",
    "fn.count_box_plot(\"use_Year\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones atributos USE:\n",
    "- Existe una asociación positiva entre Year y el precio de vehículos.\n",
    "- Existe una asociación negativa entre Mileage y el precio de los vehículos.\n",
    "- Entre year y mileage exite una fuerte asociación negativa de 0.8. Dada esta asociación, quizás es recomendable elimnar una de estas variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Distribución atributos localization (loc):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3.1 Distribución y relación de los atributos categóricos \"Loc\" con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable loc_state\n",
    "fn.count_box_plot(\"loc_State\",df, 70000,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# observamos la distribución de loc_City, mediante un plot\n",
    "df['loc_City'].value_counts().head(30).plot(kind='barh', figsize=(6,10))\n",
    "plt.title('City Distribution',fontsize=15,color='blue',fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones atributos LOC:\n",
    "\n",
    "- El precio por State presenta una distribución similar. Esto se evidencia al observar los cuartiles y la mediana de los precios en cada uno de los estados. Solo el estado DC, presenta precios inferiores. Se recomienda no considerar esta variable por el momento.\n",
    "\n",
    "- Dada la complejidad en cuanto al número de ciudades contenidas en la base de datos, por ahora no recomendamos utilizar esta variable en el proceso de entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Distribución atributos de segmentacion (sgt):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4.1 Distribución y relación de los atributos categóricos \"de segmentación \"SGT\" con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable sgt_BodyClass\n",
    "fn.count_box_plot(\"sgt_BodyClass\",df, 100000,False)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Variable sgt_VehicleType\n",
    "fn.count_box_plot(\"sgt_VehicleType\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Variable sgt_Manufacter\n",
    "fn.count_box_plot(\"sgt_Manufacturer\", df, 100000,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variable sgt_Make\n",
    "fn.count_box_plot(\"sgt_Make\", df, 500000,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observamos la distribución de sgt_model, mediante un plot\n",
    "df['sgt_Model'].value_counts().head(30).plot(kind='barh', figsize=(6,10))\n",
    "plt.title('Model Distribution',fontsize=15,color='blue',fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones atributos de segmentación (sgt):\n",
    "\n",
    "- Los atributos BodyClass, VehicleType, Make y Model y Manufacter muestran variaciones de los precios por categoría. Sin embargo, existen muchas categorías de estas variables con frecuencias muy bajas. Entonces, se recomienda utilizar estas variables previo a recodificación de las categprías marginales.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de atributos para el entrenamiento:\n",
    "Como resultado del Análisis de la distribución de los atributos y de la relación de ellos con el vector objetivo se decide seleccionar 5 atributos para la fase de entrenamiento de modelos:\n",
    "0. Price (Vector Objetivo)\n",
    "1. Mileage\n",
    "2. BodyClass\n",
    "3. PlantCountry\n",
    "4. VehicleType\n",
    "5. Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Distribución atributos de fabricación (fab):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5.1 Distribución y relación de los atributos categóricos de fabricación \"fab\" con el vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable fab_PlantCountry\n",
    "fn.count_box_plot(\"fab_PlantCountry\",df, 100000,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones atributos de fabricación (fab):\n",
    "\n",
    "- El atributo PlantCountry muestra variación de los precios entre paises. Sin embargo, también se observan frecuencias de paises marginales. Se recomienda utilizar esta variable para el entrenaminto de los datos previa recategorización.\n",
    "- Respecto al atributo PlantCity, dada la gran cantidad de ciudades se recomienda no utilizar por ahora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Recodificación de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Reagrupación de fab_PlantCountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reagrupamos el atributo fab_PlantCountry\n",
    "df['fab_PlantCountry'] = df['fab_PlantCountry'].replace(\n",
    "                         ['FRANCE','SPAIN', 'PORTUGAL', 'POLAND', 'NETHERLANDS', 'SERBIA', 'FINLAND',\"ITALY\",\"UNITED KINGDOM (UK)\",\"AUSTRIA\",\"HUNGARY\",\"ENGLAND\",\"BELGIUM\",\"SWEDEN\",\"SLOVAKIA\"],'OTHERS_EUROPE').replace(\n",
    "                         ['ARGENTINA','VENEZUELA', 'BRAZIL', 'UNITED STATES (USA), CANADA', 'CANADA, UNITED STATES (USA)'],'OTHERS_AMERICA').replace(\n",
    "                         ['THAILAND','TURKEY', 'CHINA', 'AUSTRALIA', 'INDIA'],'OTHERS_ASIA_OCEANIA').replace(\n",
    "                         [\"OTHERS_AMERICA\",\"OTHERS_ASIA_OCEANIA\",\"SOUTH AFRICA\"],\"OTHER_COUNTRIES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNITED STATES (USA)    417236\n",
       "JAPAN                   86370\n",
       "MEXICO                  83087\n",
       "CANADA                  81514\n",
       "GERMANY                 53772\n",
       "SOUTH KOREA             38222\n",
       "OTHERS_EUROPE           29065\n",
       "OTHER_COUNTRIES          8123\n",
       "Name: fab_PlantCountry, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vusalizamos la cantidad de datos para c/u de las variables de fab_PlantCountry\n",
    "df.fab_PlantCountry.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comenatrios fab_PlantCountry.\n",
    "\n",
    "Las categorías que estan por debajo de los 600 registros, se agrupan en 2 grandes conjuntos: OTHER_EUROPE y OTHER_COUNTRY.\n",
    "Como resultado de se obtienen 8 categorias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Reagrupación de sgt_BodyClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reagrupamos el atributo sgt_BodyClass\n",
    "df['sgt_BodyClass'] = df['sgt_BodyClass'].replace(\n",
    "                      [\"Hatchback/Liftback/Notchback, Convertible/Cabriolet\"],\"Hatchback/Liftback/Notchback\").replace(\n",
    "                      [\"Wagon, Sport Utility Vehicle (SUV)/Multi-Purpose Vehicle (MPV)\"],\"Wagon\").replace(\n",
    "                      [\"Incomplete - Cutaway\",\"Incomplete - Cutaway\",\"Incomplete - Chassis Cab (Number of Cab Unknown)\",\"Incomplete - Chassis Cab (Double Cab)\",\"Incomplete - Stripped Chassis\",\"Incomplete - Commercial Chassis\",\"Incomplete - Motor Home Chassis\",\"Incomplete - Chassis Cab (Single Cab)\",\"Incomplete - Chassis Cab (Double Cab) \"],\"Incomplete\").replace(\n",
    "                      [\"Truck\"],\"Sport Utility Truck (SUT)\").replace(\n",
    "                      [\"Roadster\"],\"Convertible/Cabriolet\").replace(\n",
    "                      [\"Cargo Van\"],\"Minivan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazamos con np.nan, aquellas variables del atributo sgt_BodyClass que tienen una frecuencia marginal \n",
    "df = df.replace({'sgt_BodyClass':{\"Bus\":np.NaN,\"Limousine\":np.NaN,'Trailer':np.NaN,\"Incomplete\":np.NaN}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sedan/Saloon                                               294628\n",
       "Sport Utility Vehicle (SUV)/Multi-Purpose Vehicle (MPV)    192158\n",
       "Pickup                                                     115583\n",
       "Wagon                                                      113966\n",
       "Hatchback/Liftback/Notchback                                43629\n",
       "Coupe                                                       40817\n",
       "Minivan                                                     17677\n",
       "Convertible/Cabriolet                                       15612\n",
       "Van                                                          4857\n",
       "Crossover Utility Vehicle (CUV)                              2637\n",
       "Sport Utility Truck (SUT)                                    1656\n",
       "Name: sgt_BodyClass, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vusalizamos la cantidad de datos para c/u de las variables de sgt_BodyClass\n",
    "df.sgt_BodyClass.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comentarios sgt_BodyClass\n",
    "\n",
    "Se agrupan las categorías según automóviles similares. El criterio usado fue juicio experto.\n",
    "Se decide transformar a NaN las categorías específicas: Bus, Limousine e Incomplete.\n",
    "Como resultado nos quedamos con 11 tipos de vehiculos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Reagrupación de sgt_VehicleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reemplazamos con np.nan, aquellas variables del atributo sgt_VehicleType que tienen una frecuencia marginal \n",
    "df = df.replace({'sgt_VehicleType':{\"INCOMPLETE VEHICLE\":np.NaN,\"BUS\":np.NaN,\"TRAILER\":np.NaN}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PASSENGER CAR                           395708\n",
       "MULTIPURPOSE PASSENGER VEHICLE (MPV)    326962\n",
       "TRUCK                                   119952\n",
       "Name: sgt_VehicleType, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vusalizamos los Q para c/u de las variables de sgt_VehicleType\n",
    "df.sgt_VehicleType.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comentarios sgt_VehicleType\n",
    "\n",
    "Dado que dentro del atributo `sgt_VehicleType` tenemos variables con una frecuencia muy marginal, se decide no considerarlas, por lo que se transforman a np.nan, quedandonos solo con 3 categorias de vehiculo:\n",
    "\n",
    "* De pasajeros\n",
    "* Multiproposito\n",
    "* Camión\n",
    "\n",
    "Lo que está muy relacionado con los tipos de vehiculos que comercializa una automotora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar 30 modelos\n",
    "modelos = df['sgt_Make'].value_counts()\n",
    "df = df[df['sgt_Make'].isin(modelos[modelos > 30].index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Recodificación de variable año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['use_Age'] = df['use_Year'] - 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Preproceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberar Espacio Memoria\n",
    "del df_api\n",
    "del df_data\n",
    "del df_train\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de variables para modelos\n",
    "select_vars = ['Price', 'use_Mileage', 'use_Age', 'sample', \n",
    "               'sgt_BodyClass', 'sgt_Make', 'sgt_VehicleType']\n",
    "#sample_size = df[select_vars].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra aleatoria\n",
    "df_sample = df[select_vars]\\\n",
    "                .dropna()\\\n",
    "                .sample(sample_size)\\\n",
    "                .reset_index(drop=True)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar clase para realizar preproceso\n",
    "df_prep = PrepML(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos OneHot Encoder a las columnas categóricas seleccionadas\n",
    "df_prep.one_hot_encoder(['sgt_BodyClass', 'sgt_Make', 'sgt_VehicleType'],\n",
    "                        drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>use_Mileage</th>\n",
       "      <th>use_Age</th>\n",
       "      <th>sample</th>\n",
       "      <th>sgt_BodyClass_Sport_Utility_Vehicle__SUV__Multi_Purpose_Vehicle__MPV_</th>\n",
       "      <th>sgt_BodyClass_Pickup</th>\n",
       "      <th>sgt_BodyClass_Wagon</th>\n",
       "      <th>sgt_BodyClass_Coupe</th>\n",
       "      <th>sgt_BodyClass_Hatchback_Liftback_Notchback</th>\n",
       "      <th>sgt_BodyClass_Minivan</th>\n",
       "      <th>...</th>\n",
       "      <th>sgt_Make_Mitsubishi</th>\n",
       "      <th>sgt_Make_Jaguar</th>\n",
       "      <th>sgt_Make_smart</th>\n",
       "      <th>sgt_Make_Mercury</th>\n",
       "      <th>sgt_Make_FIAT</th>\n",
       "      <th>sgt_Make_Saturn</th>\n",
       "      <th>sgt_Make_Aston</th>\n",
       "      <th>sgt_Make_Isuzu</th>\n",
       "      <th>sgt_VehicleType_MULTIPURPOSE_PASSENGER_VEHICLE__MPV_</th>\n",
       "      <th>sgt_VehicleType_TRUCK_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19899</td>\n",
       "      <td>26216</td>\n",
       "      <td>-2</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19500</td>\n",
       "      <td>55459</td>\n",
       "      <td>-6</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24950</td>\n",
       "      <td>39063</td>\n",
       "      <td>-4</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22000</td>\n",
       "      <td>58507</td>\n",
       "      <td>-4</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13997</td>\n",
       "      <td>37694</td>\n",
       "      <td>-3</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>12990</td>\n",
       "      <td>79121</td>\n",
       "      <td>-8</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>23506</td>\n",
       "      <td>33820</td>\n",
       "      <td>-2</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>15595</td>\n",
       "      <td>40616</td>\n",
       "      <td>-5</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>4900</td>\n",
       "      <td>123504</td>\n",
       "      <td>-11</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>25790</td>\n",
       "      <td>49753</td>\n",
       "      <td>-2</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Price  use_Mileage  use_Age sample  \\\n",
       "0     19899        26216       -2  train   \n",
       "1     19500        55459       -6  train   \n",
       "2     24950        39063       -4  train   \n",
       "3     22000        58507       -4  train   \n",
       "4     13997        37694       -3  train   \n",
       "...     ...          ...      ...    ...   \n",
       "1995  12990        79121       -8  train   \n",
       "1996  23506        33820       -2   test   \n",
       "1997  15595        40616       -5  train   \n",
       "1998   4900       123504      -11  train   \n",
       "1999  25790        49753       -2  train   \n",
       "\n",
       "      sgt_BodyClass_Sport_Utility_Vehicle__SUV__Multi_Purpose_Vehicle__MPV_  \\\n",
       "0                                                   0.0                       \n",
       "1                                                   0.0                       \n",
       "2                                                   0.0                       \n",
       "3                                                   0.0                       \n",
       "4                                                   0.0                       \n",
       "...                                                 ...                       \n",
       "1995                                                0.0                       \n",
       "1996                                                0.0                       \n",
       "1997                                                0.0                       \n",
       "1998                                                1.0                       \n",
       "1999                                                0.0                       \n",
       "\n",
       "      sgt_BodyClass_Pickup  sgt_BodyClass_Wagon  sgt_BodyClass_Coupe  \\\n",
       "0                      0.0                  0.0                  0.0   \n",
       "1                      0.0                  0.0                  0.0   \n",
       "2                      1.0                  0.0                  0.0   \n",
       "3                      0.0                  0.0                  0.0   \n",
       "4                      0.0                  0.0                  0.0   \n",
       "...                    ...                  ...                  ...   \n",
       "1995                   0.0                  0.0                  1.0   \n",
       "1996                   0.0                  1.0                  0.0   \n",
       "1997                   0.0                  0.0                  0.0   \n",
       "1998                   0.0                  0.0                  0.0   \n",
       "1999                   0.0                  0.0                  0.0   \n",
       "\n",
       "      sgt_BodyClass_Hatchback_Liftback_Notchback  sgt_BodyClass_Minivan  ...  \\\n",
       "0                                            0.0                    0.0  ...   \n",
       "1                                            0.0                    0.0  ...   \n",
       "2                                            0.0                    0.0  ...   \n",
       "3                                            0.0                    0.0  ...   \n",
       "4                                            1.0                    0.0  ...   \n",
       "...                                          ...                    ...  ...   \n",
       "1995                                         0.0                    0.0  ...   \n",
       "1996                                         0.0                    0.0  ...   \n",
       "1997                                         0.0                    0.0  ...   \n",
       "1998                                         0.0                    0.0  ...   \n",
       "1999                                         0.0                    0.0  ...   \n",
       "\n",
       "      sgt_Make_Mitsubishi  sgt_Make_Jaguar  sgt_Make_smart  sgt_Make_Mercury  \\\n",
       "0                     0.0              0.0             0.0               0.0   \n",
       "1                     0.0              0.0             0.0               0.0   \n",
       "2                     0.0              0.0             0.0               0.0   \n",
       "3                     0.0              0.0             0.0               0.0   \n",
       "4                     0.0              0.0             0.0               0.0   \n",
       "...                   ...              ...             ...               ...   \n",
       "1995                  0.0              0.0             0.0               0.0   \n",
       "1996                  0.0              0.0             0.0               0.0   \n",
       "1997                  0.0              0.0             0.0               0.0   \n",
       "1998                  0.0              0.0             0.0               0.0   \n",
       "1999                  0.0              0.0             0.0               0.0   \n",
       "\n",
       "      sgt_Make_FIAT  sgt_Make_Saturn  sgt_Make_Aston  sgt_Make_Isuzu  \\\n",
       "0               0.0              0.0             0.0             0.0   \n",
       "1               0.0              0.0             0.0             0.0   \n",
       "2               0.0              0.0             0.0             0.0   \n",
       "3               0.0              0.0             0.0             0.0   \n",
       "4               0.0              0.0             0.0             0.0   \n",
       "...             ...              ...             ...             ...   \n",
       "1995            0.0              0.0             0.0             0.0   \n",
       "1996            0.0              0.0             0.0             0.0   \n",
       "1997            0.0              0.0             0.0             0.0   \n",
       "1998            0.0              0.0             0.0             0.0   \n",
       "1999            0.0              0.0             0.0             0.0   \n",
       "\n",
       "      sgt_VehicleType_MULTIPURPOSE_PASSENGER_VEHICLE__MPV_  \\\n",
       "0                                                   0.0      \n",
       "1                                                   0.0      \n",
       "2                                                   0.0      \n",
       "3                                                   0.0      \n",
       "4                                                   0.0      \n",
       "...                                                 ...      \n",
       "1995                                                0.0      \n",
       "1996                                                1.0      \n",
       "1997                                                0.0      \n",
       "1998                                                1.0      \n",
       "1999                                                0.0      \n",
       "\n",
       "      sgt_VehicleType_TRUCK_  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        1.0  \n",
       "3                        0.0  \n",
       "4                        0.0  \n",
       "...                      ...  \n",
       "1995                     0.0  \n",
       "1996                     0.0  \n",
       "1997                     0.0  \n",
       "1998                     0.0  \n",
       "1999                     0.0  \n",
       "\n",
       "[2000 rows x 53 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prep.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removemos outliers (opcional)\n",
    "#df_prep.remove_outliers(['Price', 'Mileage'], multiplier=1.5)\n",
    "#df_prep.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizamos variables continuas seleccionadas\n",
    "df_prep.standard_scaler(['use_Mileage', 'use_Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizado en 0.0s\n"
     ]
    }
   ],
   "source": [
    "# Separar muestras según\n",
    "X_train, y_train, X_test, y_test = df_prep.to_train_test_samples('sample', 'Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modelamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Realizado en 0.0s\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_reg = MLModel(LinearRegression())\n",
    "linear_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 8639.1\n",
      "mae: 5543.0\n",
      "r2: 0.546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse': 8639.1, 'mae': 5543.0, 'r2': 0.546}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_reg.metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos parámetros a evaluar en el modelo\n",
    "ridge_grid = {'alpha': [0, .001, 0.0001],\n",
    "              'solver': ['sag', 'sparse_cg']}\n",
    "# Instanciamos Clase auxiliar para entrenar, ajustar y evaluar modelos de ML\n",
    "ridge_reg = MLModel(model=Ridge(fit_intercept=True))\n",
    "# Implementación del grid search\n",
    "ridge_reg.grid_search(X_train,\n",
    "                      y_train,\n",
    "                      param_grid=ridge_grid,\n",
    "                      n_jobs=3,\n",
    "                      cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas\n",
    "ridge_reg.metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos parámetros a evaluar en el modelo\n",
    "sgd_grid = {'loss': ['squared_epsilon_insensitive', 'squared_loss'],\n",
    "            'alpha': [0, 0.0001, 0.00001]\n",
    "          }\n",
    "# Instanciamos Clase auxiliar para entrenar, ajustar y evaluar modelos de ML\n",
    "sgd_reg = MLModel(model=SGDRegressor(penalty = 'l1',\n",
    "                                     early_stopping = False,\n",
    "                                     random_state=rd_seed))\n",
    "# Implementación del grid search\n",
    "sgd_reg.grid_search(X_train,\n",
    "                    y_train,\n",
    "                    param_grid=sgd_grid,\n",
    "                    n_jobs=3,\n",
    "                    cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos parámetros a evaluar en el modelo\n",
    "lgb_grid = {'max_depth': [3, 4, 5, 6], \n",
    "            'num_leaves': [30, 50, 60]}\n",
    "# Instanciamos Clase auxiliar para entrenar, ajustar y evaluar modelos de ML\n",
    "lgb_reg = MLModel(model=LGBMRegressor(n_jobs=1,\n",
    "                                      random_state=rd_seed))\n",
    "# Implementación del grid search\n",
    "lgb_reg.grid_search(X_train,\n",
    "                    y_train,\n",
    "                    param_grid=lgb_grid,\n",
    "                    n_jobs=3,\n",
    "                    cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_reg.metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos parámetros a evaluar en el modelo\n",
    "xgb_grid = {'max_depth': [4, 5, 6, 7], \n",
    "            'n_estimators': [ 60, 70, 80]}\n",
    "# Instanciamos Clase auxiliar para entrenar, ajustar y evaluar modelos de ML\n",
    "xgb_reg = MLModel(model=XGBRegressor(objective ='reg:squarederror',\n",
    "                                     n_jobs=1,\n",
    "                                     seed=rd_seed))\n",
    "# Implementación del grid search\n",
    "xgb_reg.grid_search(X_train,\n",
    "                    y_train,\n",
    "                    param_grid=xgb_grid,\n",
    "                    n_jobs=3,\n",
    "                    cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas\n",
    "xgb_reg.metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental: Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase para instanciar modelos de Keras como objetos de scikit-learn\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "# Regularizador para neuronas\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# Arquitectura secuencial para modelos de redes neuronales\n",
    "from tensorflow.keras.models import Sequential\n",
    "# Clase para conexciónes densamente pobladas\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norma de regularización con lambda=0.01\n",
    "ridge_regularizer = l2(0.0005)\n",
    "\n",
    "\n",
    "# Instanciamos la Red Neuronal\n",
    "input_dim = (X_train.shape[1],)\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu',\n",
    "                kernel_regularizer = ridge_regularizer,\n",
    "                use_bias=True, \n",
    "                input_shape=input_dim,\n",
    "                name='Primera_capa'))\n",
    "\n",
    "model.add(Dense(10, activation='relu', \n",
    "                kernel_regularizer = ridge_regularizer,\n",
    "                use_bias=True, \n",
    "                name='Segunda_capa'))\n",
    "\n",
    "model.add(Dense(1, activation='linear', use_bias=True, name='output'))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=512, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.sqrt(72202952)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
